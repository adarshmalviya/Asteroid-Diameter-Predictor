{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Asteroides Diameter Predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Necessary Liberaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50) # To see all the columns of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>condition_code</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>moid</th>\n",
       "      <th>class</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "      <th>Diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.769165</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305532</td>\n",
       "      <td>73.597694</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>1683.145708</td>\n",
       "      <td>77.372096</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.772466</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>26.665712</td>\n",
       "      <td>173.080063</td>\n",
       "      <td>310.048857</td>\n",
       "      <td>2.133865</td>\n",
       "      <td>3.411067</td>\n",
       "      <td>4.616444</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.23324</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213503</td>\n",
       "      <td>1686.155999</td>\n",
       "      <td>59.699133</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2.669150</td>\n",
       "      <td>0.256942</td>\n",
       "      <td>12.988919</td>\n",
       "      <td>169.852760</td>\n",
       "      <td>248.138626</td>\n",
       "      <td>1.983332</td>\n",
       "      <td>3.354967</td>\n",
       "      <td>4.360814</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.03454</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.226019</td>\n",
       "      <td>1592.787285</td>\n",
       "      <td>34.925016</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2.361418</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>1325.432765</td>\n",
       "      <td>95.861936</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2.574249</td>\n",
       "      <td>0.191095</td>\n",
       "      <td>5.366988</td>\n",
       "      <td>141.576605</td>\n",
       "      <td>358.687607</td>\n",
       "      <td>2.082324</td>\n",
       "      <td>3.066174</td>\n",
       "      <td>4.130323</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.09589</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>1508.600458</td>\n",
       "      <td>282.366289</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         a         e          i          om           w  \\\n",
       "0           0  2.769165  0.076009  10.594067   80.305532   73.597694   \n",
       "1           1  2.772466  0.230337  26.665712  173.080063  310.048857   \n",
       "2           2  2.669150  0.256942  12.988919  169.852760  248.138626   \n",
       "3           3  2.361418  0.088721   7.141771  103.810804  150.728541   \n",
       "4           4  2.574249  0.191095   5.366988  141.576605  358.687607   \n",
       "\n",
       "          q        ad     per_y  data_arc  condition_code  n_obs_used      H  \\\n",
       "0  2.558684  2.979647  4.608202    8822.0               0      1002.0  11.85   \n",
       "1  2.133865  3.411067  4.616444   14881.5               0      2137.5  11.85   \n",
       "2  1.983332  3.354967  4.360814   14881.5               0      2137.5  11.85   \n",
       "3  2.151909  2.570926  3.628837   14881.5               0      2137.5  11.85   \n",
       "4  2.082324  3.066174  4.130323   14881.5               0      2137.5  11.85   \n",
       "\n",
       "  neo pha     moid class         n          per          ma  Diameter  \n",
       "0   N   N  1.59478   MBA  0.213885  1683.145708   77.372096      10.2  \n",
       "1   N   N  1.23324   MBA  0.213503  1686.155999   59.699133      10.2  \n",
       "2   N   N  1.03454   MBA  0.226019  1592.787285   34.925016      10.2  \n",
       "3   N   N  1.13948   MBA  0.271609  1325.432765   95.861936      10.2  \n",
       "4   N   N  1.09589   MBA  0.238632  1508.600458  282.366289      10.2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('Clean_Dataset.csv')  # To Read dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>condition_code</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>moid</th>\n",
       "      <th>class</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "      <th>Diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.769165</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305532</td>\n",
       "      <td>73.597694</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>1683.145708</td>\n",
       "      <td>77.372096</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.772466</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>26.665712</td>\n",
       "      <td>173.080063</td>\n",
       "      <td>310.048857</td>\n",
       "      <td>2.133865</td>\n",
       "      <td>3.411067</td>\n",
       "      <td>4.616444</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.23324</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213503</td>\n",
       "      <td>1686.155999</td>\n",
       "      <td>59.699133</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.669150</td>\n",
       "      <td>0.256942</td>\n",
       "      <td>12.988919</td>\n",
       "      <td>169.852760</td>\n",
       "      <td>248.138626</td>\n",
       "      <td>1.983332</td>\n",
       "      <td>3.354967</td>\n",
       "      <td>4.360814</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.03454</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.226019</td>\n",
       "      <td>1592.787285</td>\n",
       "      <td>34.925016</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.361418</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>1325.432765</td>\n",
       "      <td>95.861936</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.574249</td>\n",
       "      <td>0.191095</td>\n",
       "      <td>5.366988</td>\n",
       "      <td>141.576605</td>\n",
       "      <td>358.687607</td>\n",
       "      <td>2.082324</td>\n",
       "      <td>3.066174</td>\n",
       "      <td>4.130323</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.09589</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>1508.600458</td>\n",
       "      <td>282.366289</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         e          i          om           w         q        ad  \\\n",
       "0  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647   \n",
       "1  2.772466  0.230337  26.665712  173.080063  310.048857  2.133865  3.411067   \n",
       "2  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   \n",
       "3  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   \n",
       "4  2.574249  0.191095   5.366988  141.576605  358.687607  2.082324  3.066174   \n",
       "\n",
       "      per_y  data_arc  condition_code  n_obs_used      H neo pha     moid  \\\n",
       "0  4.608202    8822.0               0      1002.0  11.85   N   N  1.59478   \n",
       "1  4.616444   14881.5               0      2137.5  11.85   N   N  1.23324   \n",
       "2  4.360814   14881.5               0      2137.5  11.85   N   N  1.03454   \n",
       "3  3.628837   14881.5               0      2137.5  11.85   N   N  1.13948   \n",
       "4  4.130323   14881.5               0      2137.5  11.85   N   N  1.09589   \n",
       "\n",
       "  class         n          per          ma  Diameter  \n",
       "0   MBA  0.213885  1683.145708   77.372096      10.2  \n",
       "1   MBA  0.213503  1686.155999   59.699133      10.2  \n",
       "2   MBA  0.226019  1592.787285   34.925016      10.2  \n",
       "3   MBA  0.271609  1325.432765   95.861936      10.2  \n",
       "4   MBA  0.238632  1508.600458  282.366289      10.2  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop('Unnamed: 0', axis=1, inplace=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Data :  ['neo', 'pha', 'class']\n",
      "Numeric Data :  ['a', 'e', 'i', 'om', 'w', 'q', 'ad', 'per_y', 'data_arc', 'condition_code', 'n_obs_used', 'H', 'moid', 'n', 'per', 'ma', 'Diameter']\n"
     ]
    }
   ],
   "source": [
    "# Segregate Data into numeric and categorical onces\n",
    "categorical, numeric = [], []\n",
    "for ele in dataset.columns:\n",
    "    if dataset[ele].dtype == 'object':\n",
    "        categorical.append(ele)\n",
    "    else:\n",
    "        numeric.append(ele)\n",
    "print(\"Categorical Data : \", categorical)\n",
    "print(\"Numeric Data : \", numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>per_y</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>condition_code</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>neo</th>\n",
       "      <th>pha</th>\n",
       "      <th>moid</th>\n",
       "      <th>class</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "      <th>Diameter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.769165</td>\n",
       "      <td>0.076009</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305532</td>\n",
       "      <td>73.597694</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>4.608202</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>1683.145708</td>\n",
       "      <td>77.372096</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.772466</td>\n",
       "      <td>0.230337</td>\n",
       "      <td>26.665712</td>\n",
       "      <td>173.080063</td>\n",
       "      <td>310.048857</td>\n",
       "      <td>2.133865</td>\n",
       "      <td>3.411067</td>\n",
       "      <td>4.616444</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.23324</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.213503</td>\n",
       "      <td>1686.155999</td>\n",
       "      <td>59.699133</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.669150</td>\n",
       "      <td>0.256942</td>\n",
       "      <td>12.988919</td>\n",
       "      <td>169.852760</td>\n",
       "      <td>248.138626</td>\n",
       "      <td>1.983332</td>\n",
       "      <td>3.354967</td>\n",
       "      <td>4.360814</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.03454</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.226019</td>\n",
       "      <td>1592.787285</td>\n",
       "      <td>34.925016</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.361418</td>\n",
       "      <td>0.088721</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>3.628837</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>1325.432765</td>\n",
       "      <td>95.861936</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.574249</td>\n",
       "      <td>0.191095</td>\n",
       "      <td>5.366988</td>\n",
       "      <td>141.576605</td>\n",
       "      <td>358.687607</td>\n",
       "      <td>2.082324</td>\n",
       "      <td>3.066174</td>\n",
       "      <td>4.130323</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.09589</td>\n",
       "      <td>MBA</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>1508.600458</td>\n",
       "      <td>282.366289</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          a         e          i          om           w         q        ad  \\\n",
       "0  2.769165  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647   \n",
       "1  2.772466  0.230337  26.665712  173.080063  310.048857  2.133865  3.411067   \n",
       "2  2.669150  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   \n",
       "3  2.361418  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   \n",
       "4  2.574249  0.191095   5.366988  141.576605  358.687607  2.082324  3.066174   \n",
       "\n",
       "      per_y  data_arc  condition_code  n_obs_used      H neo pha     moid  \\\n",
       "0  4.608202    8822.0               0      1002.0  11.85   N   N  1.59478   \n",
       "1  4.616444   14881.5               0      2137.5  11.85   N   N  1.23324   \n",
       "2  4.360814   14881.5               0      2137.5  11.85   N   N  1.03454   \n",
       "3  3.628837   14881.5               0      2137.5  11.85   N   N  1.13948   \n",
       "4  4.130323   14881.5               0      2137.5  11.85   N   N  1.09589   \n",
       "\n",
       "  class         n          per          ma  Diameter  \n",
       "0   MBA  0.213885  1683.145708   77.372096      10.2  \n",
       "1   MBA  0.213503  1686.155999   59.699133      10.2  \n",
       "2   MBA  0.226019  1592.787285   34.925016      10.2  \n",
       "3   MBA  0.271609  1325.432765   95.861936      10.2  \n",
       "4   MBA  0.238632  1508.600458  282.366289      10.2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for MultiCollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating VIF\n",
    "def cal_vif(X):\n",
    "\n",
    "    vif = pd.DataFrame()\n",
    "    vif['variables'] = X.columns\n",
    "    vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vif = cal_vif(dataset.drop(['neo', 'pha', 'class'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_int(x):\n",
    "    try:\n",
    "        x = int(x)\n",
    "        return x\n",
    "    except:\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>46080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>e</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>om</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>q</td>\n",
       "      <td>13356.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ad</td>\n",
       "      <td>4899.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>per_y</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>data_arc</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>condition_code</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>n_obs_used</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>H</td>\n",
       "      <td>1421.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>moid</td>\n",
       "      <td>3915.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>per</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ma</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Diameter</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         variables      VIF\n",
       "0                a  46080.0\n",
       "1                e    125.0\n",
       "2                i      6.0\n",
       "3               om      3.0\n",
       "4                w      4.0\n",
       "5                q  13356.0\n",
       "6               ad   4899.0\n",
       "7            per_y      inf\n",
       "8         data_arc     20.0\n",
       "9   condition_code      1.0\n",
       "10      n_obs_used     21.0\n",
       "11               H   1421.0\n",
       "12            moid   3915.0\n",
       "13               n    543.0\n",
       "14             per      inf\n",
       "15              ma      4.0\n",
       "16        Diameter     16.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif['VIF'] = vif['VIF'].apply(lambda x: conv_int(x))\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Variable Inflation Factor we can conclude that multicollinearity exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Droping 'per_y' and 'a' due to multicollinearity\n",
    "dataset.drop(['per_y', 'a'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Categorical Data into Numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Data :  ['neo', 'pha', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(\"Categorical Data : \",categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neo_dummy = pd.get_dummies(dataset['neo'], drop_first=True)\n",
    "neo_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Y\n",
       "0  0\n",
       "1  0\n",
       "2  0\n",
       "3  0\n",
       "4  0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pha_dummy = pd.get_dummies(dataset['pha'], drop_first=True)\n",
    "pha_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APO</th>\n",
       "      <th>AST</th>\n",
       "      <th>ATE</th>\n",
       "      <th>CEN</th>\n",
       "      <th>IMB</th>\n",
       "      <th>MBA</th>\n",
       "      <th>MCA</th>\n",
       "      <th>OMB</th>\n",
       "      <th>TJN</th>\n",
       "      <th>TNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   APO  AST  ATE  CEN  IMB  MBA  MCA  OMB  TJN  TNO\n",
       "0    0    0    0    0    0    1    0    0    0    0\n",
       "1    0    0    0    0    0    1    0    0    0    0\n",
       "2    0    0    0    0    0    1    0    0    0    0\n",
       "3    0    0    0    0    0    1    0    0    0    0\n",
       "4    0    0    0    0    0    1    0    0    0    0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_dummy = pd.get_dummies(dataset['class'], drop_first=True)\n",
    "class_dummy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>e</th>\n",
       "      <th>i</th>\n",
       "      <th>om</th>\n",
       "      <th>w</th>\n",
       "      <th>q</th>\n",
       "      <th>ad</th>\n",
       "      <th>data_arc</th>\n",
       "      <th>condition_code</th>\n",
       "      <th>n_obs_used</th>\n",
       "      <th>H</th>\n",
       "      <th>moid</th>\n",
       "      <th>n</th>\n",
       "      <th>per</th>\n",
       "      <th>ma</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Y</th>\n",
       "      <th>Y</th>\n",
       "      <th>APO</th>\n",
       "      <th>AST</th>\n",
       "      <th>ATE</th>\n",
       "      <th>CEN</th>\n",
       "      <th>IMB</th>\n",
       "      <th>MBA</th>\n",
       "      <th>MCA</th>\n",
       "      <th>OMB</th>\n",
       "      <th>TJN</th>\n",
       "      <th>TNO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.076009</td>\n",
       "      <td>10.594067</td>\n",
       "      <td>80.305532</td>\n",
       "      <td>73.597694</td>\n",
       "      <td>2.558684</td>\n",
       "      <td>2.979647</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>11.85</td>\n",
       "      <td>1.59478</td>\n",
       "      <td>0.213885</td>\n",
       "      <td>1683.145708</td>\n",
       "      <td>77.372096</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.230337</td>\n",
       "      <td>26.665712</td>\n",
       "      <td>173.080063</td>\n",
       "      <td>310.048857</td>\n",
       "      <td>2.133865</td>\n",
       "      <td>3.411067</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>1.23324</td>\n",
       "      <td>0.213503</td>\n",
       "      <td>1686.155999</td>\n",
       "      <td>59.699133</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.256942</td>\n",
       "      <td>12.988919</td>\n",
       "      <td>169.852760</td>\n",
       "      <td>248.138626</td>\n",
       "      <td>1.983332</td>\n",
       "      <td>3.354967</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>1.03454</td>\n",
       "      <td>0.226019</td>\n",
       "      <td>1592.787285</td>\n",
       "      <td>34.925016</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.088721</td>\n",
       "      <td>7.141771</td>\n",
       "      <td>103.810804</td>\n",
       "      <td>150.728541</td>\n",
       "      <td>2.151909</td>\n",
       "      <td>2.570926</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>1.13948</td>\n",
       "      <td>0.271609</td>\n",
       "      <td>1325.432765</td>\n",
       "      <td>95.861936</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.191095</td>\n",
       "      <td>5.366988</td>\n",
       "      <td>141.576605</td>\n",
       "      <td>358.687607</td>\n",
       "      <td>2.082324</td>\n",
       "      <td>3.066174</td>\n",
       "      <td>14881.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2137.5</td>\n",
       "      <td>11.85</td>\n",
       "      <td>1.09589</td>\n",
       "      <td>0.238632</td>\n",
       "      <td>1508.600458</td>\n",
       "      <td>282.366289</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          e          i          om           w         q        ad  data_arc  \\\n",
       "0  0.076009  10.594067   80.305532   73.597694  2.558684  2.979647    8822.0   \n",
       "1  0.230337  26.665712  173.080063  310.048857  2.133865  3.411067   14881.5   \n",
       "2  0.256942  12.988919  169.852760  248.138626  1.983332  3.354967   14881.5   \n",
       "3  0.088721   7.141771  103.810804  150.728541  2.151909  2.570926   14881.5   \n",
       "4  0.191095   5.366988  141.576605  358.687607  2.082324  3.066174   14881.5   \n",
       "\n",
       "   condition_code  n_obs_used      H     moid         n          per  \\\n",
       "0               0      1002.0  11.85  1.59478  0.213885  1683.145708   \n",
       "1               0      2137.5  11.85  1.23324  0.213503  1686.155999   \n",
       "2               0      2137.5  11.85  1.03454  0.226019  1592.787285   \n",
       "3               0      2137.5  11.85  1.13948  0.271609  1325.432765   \n",
       "4               0      2137.5  11.85  1.09589  0.238632  1508.600458   \n",
       "\n",
       "           ma  Diameter  Y  Y  APO  AST  ATE  CEN  IMB  MBA  MCA  OMB  TJN  \\\n",
       "0   77.372096      10.2  0  0    0    0    0    0    0    1    0    0    0   \n",
       "1   59.699133      10.2  0  0    0    0    0    0    0    1    0    0    0   \n",
       "2   34.925016      10.2  0  0    0    0    0    0    0    1    0    0    0   \n",
       "3   95.861936      10.2  0  0    0    0    0    0    0    1    0    0    0   \n",
       "4  282.366289      10.2  0  0    0    0    0    0    0    1    0    0    0   \n",
       "\n",
       "   TNO  \n",
       "0    0  \n",
       "1    0  \n",
       "2    0  \n",
       "3    0  \n",
       "4    0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = pd.concat([dataset, neo_dummy, pha_dummy, class_dummy], axis=1)\n",
    "new_data.drop(['neo', 'pha', 'class'], axis=1, inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data into Train and Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_data.drop('Diameter', axis=1), new_data['Diameter'], test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_scale = StandardScaler()\n",
    "X_train = sc_scale.fit_transform(X_train)\n",
    "X_test = sc_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_pred, y_actual):\n",
    "    mae = mean_absolute_error(y_actual, y_pred)\n",
    "    mse = mean_squared_error(y_actual, y_pred)\n",
    "    rmse = sqrt(mse)\n",
    "    r2 = r2_score(y_actual, y_pred)\n",
    "\n",
    "    print(\"Mean Absolute Error :-> \", mae)\n",
    "    print(\"Mean Squared Error :-> \", mse)\n",
    "    print(\"Root Mean Squared Error :-> \", rmse)\n",
    "    print(\"R-Square :-> \", r2)\n",
    "\n",
    "    return mae, mse, rmse, r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score = {}     # For Storing Algoriths name and its performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_reg = RandomForestRegressor()\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = rf_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.680833062094353\n",
      "Mean Squared Error :->  0.9194034228717037\n",
      "Root Mean Squared Error :->  0.9588552669051277\n",
      "R-Square :->  0.8128859709004848\n"
     ]
    }
   ],
   "source": [
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['Random Forest'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Nearest Neighbour Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn = KNeighborsRegressor(n_neighbors=4)\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.7664552213503826\n",
      "Mean Squared Error :->  1.1998944622566112\n",
      "Root Mean Squared Error :->  1.0953969427822094\n",
      "R-Square :->  0.7530723645360814\n"
     ]
    }
   ],
   "source": [
    "y_pred_knn = knn.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['K Nearest Neighbour'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linear_r = LinearRegression()\n",
    "linear_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  1.0348816875261375\n",
      "Mean Squared Error :->  1.582379557374306\n",
      "Root Mean Squared Error :->  1.2579266899840809\n",
      "R-Square :->  0.6347610251786897\n"
     ]
    }
   ],
   "source": [
    "y_pred_linear = linear_r.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['Linear Regression'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.9141836191029789\n",
      "Mean Squared Error :->  1.907110879831444\n",
      "Root Mean Squared Error :->  1.380981853548932\n",
      "R-Square :->  0.6771680509260982\n"
     ]
    }
   ],
   "source": [
    "y_pred_tree = tree.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['Decision Tree'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "             colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "             importance_type='gain', interaction_constraints='',\n",
       "             learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "             min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "             n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "             reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "             tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb_r = XGBRegressor()\n",
    "xgb_r.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.6948326724081824\n",
      "Mean Squared Error :->  0.9323081115146016\n",
      "Root Mean Squared Error :->  0.9655610345879755\n",
      "R-Square :->  0.812554056935533\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb = xgb_r.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['XG Boost'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost with Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining HyperParameters\n",
    "hyper_param = {'learning_rate':[0.290,0.30,0.301],\n",
    "    'max_depth':[4,6,8],\n",
    "    'min_child_weight':[1,3],\n",
    "    'gamma':[0,0.1,0.2],\n",
    "    'colsample_bytree':[0.9,1,1.1],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using RandomizedSearchCV for finding the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(xgb_r,param_distributions=hyper_param,n_jobs=-1, scoring=\"neg_mean_squared_error\",cv=3, verbose=3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          gpu_id=-1, importance_type='gain',\n",
       "                                          interaction_constraints='',\n",
       "                                          learning_rate=0.300000012,\n",
       "                                          max_delta_step=0, max_depth=6,\n",
       "                                          min_child_weight=1, missing=nan,\n",
       "                                          monotone_constraints='()',\n",
       "                                          n_estimators=100, n_jobs=8,\n",
       "                                          num_par..., random_state=0,\n",
       "                                          reg_alpha=0, reg_lambda=1,\n",
       "                                          scale_pos_weight=1, subsample=1,\n",
       "                                          tree_method='exact',\n",
       "                                          validate_parameters=1,\n",
       "                                          verbosity=None),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'colsample_bytree': [0.9, 1, 1.1],\n",
       "                                        'gamma': [0, 0.1, 0.2],\n",
       "                                        'learning_rate': [0.29, 0.3, 0.301],\n",
       "                                        'max_depth': [4, 6, 8],\n",
       "                                        'min_child_weight': [1, 3]},\n",
       "                   random_state=10, scoring='neg_mean_squared_error',\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters found are : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'min_child_weight': 1,\n",
       " 'max_depth': 8,\n",
       " 'learning_rate': 0.301,\n",
       " 'gamma': 0.2,\n",
       " 'colsample_bytree': 1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Best Parameters found are : \")\n",
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.6836185218052057\n",
      "Mean Squared Error :->  0.9245212438376977\n",
      "Root Mean Squared Error :->  0.9615202773928887\n",
      "R-Square :->  0.8170610040695809\n"
     ]
    }
   ],
   "source": [
    "y_pred_xgb_opt = random_search.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_xgb_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['Optimized XG Boost'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artificial Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann = Sequential()\n",
    "ann.add(Dense(input_dim=X_train.shape[1], units=12, kernel_initializer=\"he_uniform\", activation=\"relu\"))\n",
    "ann.add(Dense(units=10, kernel_initializer=\"he_uniform\", activation=\"relu\"))\n",
    "ann.add(Dense(units=1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                324       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                130       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 465\n",
      "Trainable params: 465\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 4.5591 - val_loss: 1.5033\n",
      "Epoch 2/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.4032 - val_loss: 1.3385\n",
      "Epoch 3/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.3103 - val_loss: 1.2956\n",
      "Epoch 4/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2788 - val_loss: 1.2815\n",
      "Epoch 5/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2594 - val_loss: 1.2476\n",
      "Epoch 6/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2434 - val_loss: 1.2414\n",
      "Epoch 7/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2315 - val_loss: 1.2273\n",
      "Epoch 8/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2214 - val_loss: 1.2204\n",
      "Epoch 9/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2108 - val_loss: 1.2073\n",
      "Epoch 10/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.2030 - val_loss: 1.1950\n",
      "Epoch 11/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.1950 - val_loss: 1.1903\n",
      "Epoch 12/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.1865 - val_loss: 1.1760\n",
      "Epoch 13/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.1777 - val_loss: 1.1755\n",
      "Epoch 14/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.1714 - val_loss: 1.1709\n",
      "Epoch 15/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1655 - val_loss: 1.1585\n",
      "Epoch 16/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1576 - val_loss: 1.1492\n",
      "Epoch 17/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.1499 - val_loss: 1.1536\n",
      "Epoch 18/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1429 - val_loss: 1.1409\n",
      "Epoch 19/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1382 - val_loss: 1.1345\n",
      "Epoch 20/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1339 - val_loss: 1.1281\n",
      "Epoch 21/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1292 - val_loss: 1.1249\n",
      "Epoch 22/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1250 - val_loss: 1.1335\n",
      "Epoch 23/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1243 - val_loss: 1.1192\n",
      "Epoch 24/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1196 - val_loss: 1.1160\n",
      "Epoch 25/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1175 - val_loss: 1.1172\n",
      "Epoch 26/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.1153 - val_loss: 1.1149\n",
      "Epoch 27/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.1140 - val_loss: 1.1159\n",
      "Epoch 28/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1113 - val_loss: 1.1228\n",
      "Epoch 29/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1116 - val_loss: 1.1173\n",
      "Epoch 30/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1106 - val_loss: 1.1096\n",
      "Epoch 31/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1072 - val_loss: 1.1027\n",
      "Epoch 32/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1061 - val_loss: 1.1040\n",
      "Epoch 33/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1041 - val_loss: 1.1055\n",
      "Epoch 34/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1047 - val_loss: 1.1024\n",
      "Epoch 35/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.1036 - val_loss: 1.1068\n",
      "Epoch 36/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1035 - val_loss: 1.1017\n",
      "Epoch 37/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1018 - val_loss: 1.1054\n",
      "Epoch 38/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.1005 - val_loss: 1.1011\n",
      "Epoch 39/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0999 - val_loss: 1.1064\n",
      "Epoch 40/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0995 - val_loss: 1.1090\n",
      "Epoch 41/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0984 - val_loss: 1.0932\n",
      "Epoch 42/200\n",
      "819/819 [==============================] - 1s 967us/step - loss: 1.0983 - val_loss: 1.1133\n",
      "Epoch 43/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0975 - val_loss: 1.0969\n",
      "Epoch 44/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0959 - val_loss: 1.1003\n",
      "Epoch 45/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0962 - val_loss: 1.0958\n",
      "Epoch 46/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0966 - val_loss: 1.1059\n",
      "Epoch 47/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0966 - val_loss: 1.0908\n",
      "Epoch 48/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0964 - val_loss: 1.0897\n",
      "Epoch 49/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0948 - val_loss: 1.0892\n",
      "Epoch 50/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0944 - val_loss: 1.0945\n",
      "Epoch 51/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0939 - val_loss: 1.0899\n",
      "Epoch 52/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0923 - val_loss: 1.0963\n",
      "Epoch 53/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0930 - val_loss: 1.0923\n",
      "Epoch 54/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0934 - val_loss: 1.0896\n",
      "Epoch 55/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0916 - val_loss: 1.0882\n",
      "Epoch 56/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0904 - val_loss: 1.0899\n",
      "Epoch 57/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0906 - val_loss: 1.0897\n",
      "Epoch 58/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0906 - val_loss: 1.0955\n",
      "Epoch 59/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0890 - val_loss: 1.0968\n",
      "Epoch 60/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0896 - val_loss: 1.0891\n",
      "Epoch 61/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0892 - val_loss: 1.0912\n",
      "Epoch 62/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0885 - val_loss: 1.0892\n",
      "Epoch 63/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0875 - val_loss: 1.0931\n",
      "Epoch 64/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0869 - val_loss: 1.0854\n",
      "Epoch 65/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0872 - val_loss: 1.0877\n",
      "Epoch 66/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0858 - val_loss: 1.0920\n",
      "Epoch 67/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0861 - val_loss: 1.0931\n",
      "Epoch 68/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0843 - val_loss: 1.0914\n",
      "Epoch 69/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0855 - val_loss: 1.0865\n",
      "Epoch 70/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0843 - val_loss: 1.1142\n",
      "Epoch 71/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0840 - val_loss: 1.0859\n",
      "Epoch 72/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0839 - val_loss: 1.0898\n",
      "Epoch 73/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0841 - val_loss: 1.0922\n",
      "Epoch 74/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0827 - val_loss: 1.0860\n",
      "Epoch 75/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0824 - val_loss: 1.0880\n",
      "Epoch 76/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0821 - val_loss: 1.0932\n",
      "Epoch 77/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0818 - val_loss: 1.0931\n",
      "Epoch 78/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0823 - val_loss: 1.0969\n",
      "Epoch 79/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0826 - val_loss: 1.0917\n",
      "Epoch 80/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0829 - val_loss: 1.0843\n",
      "Epoch 81/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0832 - val_loss: 1.0873\n",
      "Epoch 82/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0817 - val_loss: 1.0855\n",
      "Epoch 83/200\n",
      "819/819 [==============================] - 1s 893us/step - loss: 1.0825 - val_loss: 1.0859\n",
      "Epoch 84/200\n",
      "819/819 [==============================] - 1s 922us/step - loss: 1.0819 - val_loss: 1.0942\n",
      "Epoch 85/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0807 - val_loss: 1.0844\n",
      "Epoch 86/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0810 - val_loss: 1.0875\n",
      "Epoch 87/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0799 - val_loss: 1.0913\n",
      "Epoch 88/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0814 - val_loss: 1.0827\n",
      "Epoch 89/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0823 - val_loss: 1.0845\n",
      "Epoch 90/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0799 - val_loss: 1.0857\n",
      "Epoch 91/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0798 - val_loss: 1.0918\n",
      "Epoch 92/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0798 - val_loss: 1.0813\n",
      "Epoch 93/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0803 - val_loss: 1.0846\n",
      "Epoch 94/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0797 - val_loss: 1.0882\n",
      "Epoch 95/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0798 - val_loss: 1.0882\n",
      "Epoch 96/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0803 - val_loss: 1.0820\n",
      "Epoch 97/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0790 - val_loss: 1.0804\n",
      "Epoch 98/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0787 - val_loss: 1.0879\n",
      "Epoch 99/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0796 - val_loss: 1.0824\n",
      "Epoch 100/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0788 - val_loss: 1.0819\n",
      "Epoch 101/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0766 - val_loss: 1.0871\n",
      "Epoch 102/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0768 - val_loss: 1.0789\n",
      "Epoch 103/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0771 - val_loss: 1.0854\n",
      "Epoch 104/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0771 - val_loss: 1.0835\n",
      "Epoch 105/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0766 - val_loss: 1.0802\n",
      "Epoch 106/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0757 - val_loss: 1.0814\n",
      "Epoch 107/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0762 - val_loss: 1.0881\n",
      "Epoch 108/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0765 - val_loss: 1.0831\n",
      "Epoch 109/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0759 - val_loss: 1.0834\n",
      "Epoch 110/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0753 - val_loss: 1.0860\n",
      "Epoch 111/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0750 - val_loss: 1.0921\n",
      "Epoch 112/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0748 - val_loss: 1.0909\n",
      "Epoch 113/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0754 - val_loss: 1.0778\n",
      "Epoch 114/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0736 - val_loss: 1.0788\n",
      "Epoch 115/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0736 - val_loss: 1.0765\n",
      "Epoch 116/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0732 - val_loss: 1.0773\n",
      "Epoch 117/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0738 - val_loss: 1.0867\n",
      "Epoch 118/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0741 - val_loss: 1.0821\n",
      "Epoch 119/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0723 - val_loss: 1.0752\n",
      "Epoch 120/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0731 - val_loss: 1.0782\n",
      "Epoch 121/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0730 - val_loss: 1.0726\n",
      "Epoch 122/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0729 - val_loss: 1.0751\n",
      "Epoch 123/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0725 - val_loss: 1.0799\n",
      "Epoch 124/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0720 - val_loss: 1.0796\n",
      "Epoch 125/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0719 - val_loss: 1.0769\n",
      "Epoch 126/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0723 - val_loss: 1.0829\n",
      "Epoch 127/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0733 - val_loss: 1.0832\n",
      "Epoch 128/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0714 - val_loss: 1.0841\n",
      "Epoch 129/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0714 - val_loss: 1.0797\n",
      "Epoch 130/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0724 - val_loss: 1.0785\n",
      "Epoch 131/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0719 - val_loss: 1.0800\n",
      "Epoch 132/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0716 - val_loss: 1.0919\n",
      "Epoch 133/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0703 - val_loss: 1.0786\n",
      "Epoch 134/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0711 - val_loss: 1.0920\n",
      "Epoch 135/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0712 - val_loss: 1.0772\n",
      "Epoch 136/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0710 - val_loss: 1.0759\n",
      "Epoch 137/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0710 - val_loss: 1.0877\n",
      "Epoch 138/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0705 - val_loss: 1.0945\n",
      "Epoch 139/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0704 - val_loss: 1.0838\n",
      "Epoch 140/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0705 - val_loss: 1.0761\n",
      "Epoch 141/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0704 - val_loss: 1.0893\n",
      "Epoch 142/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0708 - val_loss: 1.0814\n",
      "Epoch 143/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0704 - val_loss: 1.0741\n",
      "Epoch 144/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0692 - val_loss: 1.0773\n",
      "Epoch 145/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0699 - val_loss: 1.0760\n",
      "Epoch 146/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0690 - val_loss: 1.0760\n",
      "Epoch 147/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0687 - val_loss: 1.0768\n",
      "Epoch 148/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0700 - val_loss: 1.0763\n",
      "Epoch 149/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0684 - val_loss: 1.0757\n",
      "Epoch 150/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0677 - val_loss: 1.0744\n",
      "Epoch 151/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0697 - val_loss: 1.0871\n",
      "Epoch 152/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0688 - val_loss: 1.0746\n",
      "Epoch 153/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0683 - val_loss: 1.0726\n",
      "Epoch 154/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0688 - val_loss: 1.0782\n",
      "Epoch 155/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0682 - val_loss: 1.0747\n",
      "Epoch 156/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0687 - val_loss: 1.0744\n",
      "Epoch 157/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0678 - val_loss: 1.0739\n",
      "Epoch 158/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0676 - val_loss: 1.0790\n",
      "Epoch 159/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0674 - val_loss: 1.0733\n",
      "Epoch 160/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0667 - val_loss: 1.0778\n",
      "Epoch 161/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0670 - val_loss: 1.0814\n",
      "Epoch 162/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0662 - val_loss: 1.0806\n",
      "Epoch 163/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0676 - val_loss: 1.0706\n",
      "Epoch 164/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0673 - val_loss: 1.0700\n",
      "Epoch 165/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0675 - val_loss: 1.0774\n",
      "Epoch 166/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0670 - val_loss: 1.0801\n",
      "Epoch 167/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0661 - val_loss: 1.0686\n",
      "Epoch 168/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0659 - val_loss: 1.0691\n",
      "Epoch 169/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0670 - val_loss: 1.0733\n",
      "Epoch 170/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0661 - val_loss: 1.0672\n",
      "Epoch 171/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0669 - val_loss: 1.0782\n",
      "Epoch 172/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0675 - val_loss: 1.0730\n",
      "Epoch 173/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0659 - val_loss: 1.0739\n",
      "Epoch 174/200\n",
      "819/819 [==============================] - 1s 1ms/step - loss: 1.0661 - val_loss: 1.0698\n",
      "Epoch 175/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0666 - val_loss: 1.0715\n",
      "Epoch 176/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0665 - val_loss: 1.0712\n",
      "Epoch 177/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0652 - val_loss: 1.0759\n",
      "Epoch 178/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0654 - val_loss: 1.0715\n",
      "Epoch 179/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0657 - val_loss: 1.0721\n",
      "Epoch 180/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0663 - val_loss: 1.0845\n",
      "Epoch 181/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0663 - val_loss: 1.0674\n",
      "Epoch 182/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0678 - val_loss: 1.0782\n",
      "Epoch 183/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0649 - val_loss: 1.0682\n",
      "Epoch 184/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0653 - val_loss: 1.0702\n",
      "Epoch 185/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0649 - val_loss: 1.0699\n",
      "Epoch 186/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0658 - val_loss: 1.0755\n",
      "Epoch 187/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0659 - val_loss: 1.0676\n",
      "Epoch 188/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0650 - val_loss: 1.0736\n",
      "Epoch 189/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0650 - val_loss: 1.0713\n",
      "Epoch 190/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0651 - val_loss: 1.0741\n",
      "Epoch 191/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0654 - val_loss: 1.0677\n",
      "Epoch 192/200\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 1.0647 - val_loss: 1.0717\n",
      "Epoch 193/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0656 - val_loss: 1.0682\n",
      "Epoch 194/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0646 - val_loss: 1.0690\n",
      "Epoch 195/200\n",
      "819/819 [==============================] - 3s 3ms/step - loss: 1.0648 - val_loss: 1.0709\n",
      "Epoch 196/200\n",
      "819/819 [==============================] - 2s 3ms/step - loss: 1.0644 - val_loss: 1.0728\n",
      "Epoch 197/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0645 - val_loss: 1.0692\n",
      "Epoch 198/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0645 - val_loss: 1.0766\n",
      "Epoch 199/200\n",
      "819/819 [==============================] - 1s 2ms/step - loss: 1.0651 - val_loss: 1.0685\n",
      "Epoch 200/200\n",
      "819/819 [==============================] - 2s 2ms/step - loss: 1.0643 - val_loss: 1.0712\n"
     ]
    }
   ],
   "source": [
    "ann_r = ann.fit(X_train, y_train, validation_split=0.3, epochs=200, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.7531538485264399\n",
      "Mean Squared Error :->  1.0512824336108177\n",
      "Root Mean Squared Error :->  1.0253206491682578\n",
      "R-Square :->  0.783089789445651\n"
     ]
    }
   ],
   "source": [
    "y_pred_ann = ann.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['ANN'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CatBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.086885\n",
      "0:\tlearn: 2.2702412\ttotal: 166ms\tremaining: 2m 46s\n",
      "1:\tlearn: 2.1350004\ttotal: 181ms\tremaining: 1m 30s\n",
      "2:\tlearn: 2.0138195\ttotal: 194ms\tremaining: 1m 4s\n",
      "3:\tlearn: 1.9034171\ttotal: 210ms\tremaining: 52.3s\n",
      "4:\tlearn: 1.8067210\ttotal: 226ms\tremaining: 44.9s\n",
      "5:\tlearn: 1.7201327\ttotal: 242ms\tremaining: 40.1s\n",
      "6:\tlearn: 1.6430399\ttotal: 259ms\tremaining: 36.8s\n",
      "7:\tlearn: 1.5741581\ttotal: 280ms\tremaining: 34.7s\n",
      "8:\tlearn: 1.5135068\ttotal: 300ms\tremaining: 33.1s\n",
      "9:\tlearn: 1.4609188\ttotal: 344ms\tremaining: 34s\n",
      "10:\tlearn: 1.4130998\ttotal: 364ms\tremaining: 32.8s\n",
      "11:\tlearn: 1.3721620\ttotal: 393ms\tremaining: 32.4s\n",
      "12:\tlearn: 1.3373936\ttotal: 415ms\tremaining: 31.5s\n",
      "13:\tlearn: 1.3050881\ttotal: 438ms\tremaining: 30.8s\n",
      "14:\tlearn: 1.2774789\ttotal: 457ms\tremaining: 30s\n",
      "15:\tlearn: 1.2533841\ttotal: 479ms\tremaining: 29.5s\n",
      "16:\tlearn: 1.2322848\ttotal: 499ms\tremaining: 28.9s\n",
      "17:\tlearn: 1.2137205\ttotal: 520ms\tremaining: 28.4s\n",
      "18:\tlearn: 1.1979434\ttotal: 556ms\tremaining: 28.7s\n",
      "19:\tlearn: 1.1840838\ttotal: 575ms\tremaining: 28.2s\n",
      "20:\tlearn: 1.1716216\ttotal: 591ms\tremaining: 27.6s\n",
      "21:\tlearn: 1.1609770\ttotal: 608ms\tremaining: 27s\n",
      "22:\tlearn: 1.1516268\ttotal: 626ms\tremaining: 26.6s\n",
      "23:\tlearn: 1.1435269\ttotal: 646ms\tremaining: 26.3s\n",
      "24:\tlearn: 1.1364227\ttotal: 662ms\tremaining: 25.8s\n",
      "25:\tlearn: 1.1298228\ttotal: 683ms\tremaining: 25.6s\n",
      "26:\tlearn: 1.1241647\ttotal: 702ms\tremaining: 25.3s\n",
      "27:\tlearn: 1.1187838\ttotal: 726ms\tremaining: 25.2s\n",
      "28:\tlearn: 1.1139793\ttotal: 749ms\tremaining: 25.1s\n",
      "29:\tlearn: 1.1096113\ttotal: 767ms\tremaining: 24.8s\n",
      "30:\tlearn: 1.1057772\ttotal: 784ms\tremaining: 24.5s\n",
      "31:\tlearn: 1.1027364\ttotal: 803ms\tremaining: 24.3s\n",
      "32:\tlearn: 1.0996673\ttotal: 824ms\tremaining: 24.1s\n",
      "33:\tlearn: 1.0963443\ttotal: 846ms\tremaining: 24s\n",
      "34:\tlearn: 1.0937531\ttotal: 866ms\tremaining: 23.9s\n",
      "35:\tlearn: 1.0915823\ttotal: 882ms\tremaining: 23.6s\n",
      "36:\tlearn: 1.0897320\ttotal: 896ms\tremaining: 23.3s\n",
      "37:\tlearn: 1.0884118\ttotal: 910ms\tremaining: 23s\n",
      "38:\tlearn: 1.0870904\ttotal: 924ms\tremaining: 22.8s\n",
      "39:\tlearn: 1.0846898\ttotal: 940ms\tremaining: 22.6s\n",
      "40:\tlearn: 1.0832558\ttotal: 954ms\tremaining: 22.3s\n",
      "41:\tlearn: 1.0807052\ttotal: 974ms\tremaining: 22.2s\n",
      "42:\tlearn: 1.0793177\ttotal: 990ms\tremaining: 22s\n",
      "43:\tlearn: 1.0783507\ttotal: 1s\tremaining: 21.8s\n",
      "44:\tlearn: 1.0774059\ttotal: 1.02s\tremaining: 21.6s\n",
      "45:\tlearn: 1.0765251\ttotal: 1.03s\tremaining: 21.4s\n",
      "46:\tlearn: 1.0754594\ttotal: 1.04s\tremaining: 21.2s\n",
      "47:\tlearn: 1.0747979\ttotal: 1.05s\tremaining: 20.9s\n",
      "48:\tlearn: 1.0724469\ttotal: 1.07s\tremaining: 20.8s\n",
      "49:\tlearn: 1.0718773\ttotal: 1.08s\tremaining: 20.5s\n",
      "50:\tlearn: 1.0712528\ttotal: 1.09s\tremaining: 20.3s\n",
      "51:\tlearn: 1.0704359\ttotal: 1.1s\tremaining: 20.2s\n",
      "52:\tlearn: 1.0688715\ttotal: 1.12s\tremaining: 20s\n",
      "53:\tlearn: 1.0679540\ttotal: 1.13s\tremaining: 19.9s\n",
      "54:\tlearn: 1.0668692\ttotal: 1.15s\tremaining: 19.7s\n",
      "55:\tlearn: 1.0661992\ttotal: 1.16s\tremaining: 19.6s\n",
      "56:\tlearn: 1.0657237\ttotal: 1.18s\tremaining: 19.5s\n",
      "57:\tlearn: 1.0653156\ttotal: 1.19s\tremaining: 19.3s\n",
      "58:\tlearn: 1.0644983\ttotal: 1.2s\tremaining: 19.2s\n",
      "59:\tlearn: 1.0635003\ttotal: 1.21s\tremaining: 19s\n",
      "60:\tlearn: 1.0621169\ttotal: 1.23s\tremaining: 18.9s\n",
      "61:\tlearn: 1.0616624\ttotal: 1.24s\tremaining: 18.8s\n",
      "62:\tlearn: 1.0607874\ttotal: 1.25s\tremaining: 18.6s\n",
      "63:\tlearn: 1.0602534\ttotal: 1.26s\tremaining: 18.5s\n",
      "64:\tlearn: 1.0594478\ttotal: 1.28s\tremaining: 18.4s\n",
      "65:\tlearn: 1.0587130\ttotal: 1.29s\tremaining: 18.3s\n",
      "66:\tlearn: 1.0582043\ttotal: 1.31s\tremaining: 18.2s\n",
      "67:\tlearn: 1.0572242\ttotal: 1.32s\tremaining: 18.1s\n",
      "68:\tlearn: 1.0557618\ttotal: 1.33s\tremaining: 18s\n",
      "69:\tlearn: 1.0549165\ttotal: 1.35s\tremaining: 17.9s\n",
      "70:\tlearn: 1.0539030\ttotal: 1.36s\tremaining: 17.8s\n",
      "71:\tlearn: 1.0531945\ttotal: 1.38s\tremaining: 17.8s\n",
      "72:\tlearn: 1.0523342\ttotal: 1.39s\tremaining: 17.7s\n",
      "73:\tlearn: 1.0517504\ttotal: 1.41s\tremaining: 17.7s\n",
      "74:\tlearn: 1.0507083\ttotal: 1.43s\tremaining: 17.6s\n",
      "75:\tlearn: 1.0499787\ttotal: 1.44s\tremaining: 17.5s\n",
      "76:\tlearn: 1.0496142\ttotal: 1.46s\tremaining: 17.5s\n",
      "77:\tlearn: 1.0490712\ttotal: 1.47s\tremaining: 17.4s\n",
      "78:\tlearn: 1.0482624\ttotal: 1.49s\tremaining: 17.4s\n",
      "79:\tlearn: 1.0478033\ttotal: 1.5s\tremaining: 17.3s\n",
      "80:\tlearn: 1.0471198\ttotal: 1.51s\tremaining: 17.2s\n",
      "81:\tlearn: 1.0462889\ttotal: 1.53s\tremaining: 17.1s\n",
      "82:\tlearn: 1.0457169\ttotal: 1.54s\tremaining: 17s\n",
      "83:\tlearn: 1.0450365\ttotal: 1.56s\tremaining: 17s\n",
      "84:\tlearn: 1.0438830\ttotal: 1.57s\tremaining: 16.9s\n",
      "85:\tlearn: 1.0429398\ttotal: 1.59s\tremaining: 16.9s\n",
      "86:\tlearn: 1.0423583\ttotal: 1.6s\tremaining: 16.8s\n",
      "87:\tlearn: 1.0415248\ttotal: 1.62s\tremaining: 16.8s\n",
      "88:\tlearn: 1.0408052\ttotal: 1.64s\tremaining: 16.7s\n",
      "89:\tlearn: 1.0405809\ttotal: 1.65s\tremaining: 16.7s\n",
      "90:\tlearn: 1.0401662\ttotal: 1.67s\tremaining: 16.7s\n",
      "91:\tlearn: 1.0392961\ttotal: 1.7s\tremaining: 16.8s\n",
      "92:\tlearn: 1.0389845\ttotal: 1.72s\tremaining: 16.8s\n",
      "93:\tlearn: 1.0385723\ttotal: 1.75s\tremaining: 16.8s\n",
      "94:\tlearn: 1.0380389\ttotal: 1.77s\tremaining: 16.8s\n",
      "95:\tlearn: 1.0374078\ttotal: 1.79s\tremaining: 16.8s\n",
      "96:\tlearn: 1.0370123\ttotal: 1.8s\tremaining: 16.8s\n",
      "97:\tlearn: 1.0364024\ttotal: 1.82s\tremaining: 16.8s\n",
      "98:\tlearn: 1.0356793\ttotal: 1.84s\tremaining: 16.8s\n",
      "99:\tlearn: 1.0350334\ttotal: 1.86s\tremaining: 16.8s\n",
      "100:\tlearn: 1.0347334\ttotal: 1.89s\tremaining: 16.8s\n",
      "101:\tlearn: 1.0340331\ttotal: 1.91s\tremaining: 16.8s\n",
      "102:\tlearn: 1.0333994\ttotal: 1.94s\tremaining: 16.9s\n",
      "103:\tlearn: 1.0327718\ttotal: 1.97s\tremaining: 17s\n",
      "104:\tlearn: 1.0324405\ttotal: 1.99s\tremaining: 17s\n",
      "105:\tlearn: 1.0318096\ttotal: 2.02s\tremaining: 17s\n",
      "106:\tlearn: 1.0312658\ttotal: 2.04s\tremaining: 17s\n",
      "107:\tlearn: 1.0305923\ttotal: 2.06s\tremaining: 17s\n",
      "108:\tlearn: 1.0300015\ttotal: 2.08s\tremaining: 17.1s\n",
      "109:\tlearn: 1.0295573\ttotal: 2.11s\tremaining: 17s\n",
      "110:\tlearn: 1.0291279\ttotal: 2.13s\tremaining: 17.1s\n",
      "111:\tlearn: 1.0284428\ttotal: 2.16s\tremaining: 17.1s\n",
      "112:\tlearn: 1.0281257\ttotal: 2.18s\tremaining: 17.1s\n",
      "113:\tlearn: 1.0277435\ttotal: 2.2s\tremaining: 17.1s\n",
      "114:\tlearn: 1.0272219\ttotal: 2.22s\tremaining: 17.1s\n",
      "115:\tlearn: 1.0268996\ttotal: 2.24s\tremaining: 17.1s\n",
      "116:\tlearn: 1.0266641\ttotal: 2.25s\tremaining: 17s\n",
      "117:\tlearn: 1.0262368\ttotal: 2.27s\tremaining: 17s\n",
      "118:\tlearn: 1.0257957\ttotal: 2.29s\tremaining: 17s\n",
      "119:\tlearn: 1.0255688\ttotal: 2.31s\tremaining: 17s\n",
      "120:\tlearn: 1.0250322\ttotal: 2.33s\tremaining: 17s\n",
      "121:\tlearn: 1.0244695\ttotal: 2.35s\tremaining: 16.9s\n",
      "122:\tlearn: 1.0238321\ttotal: 2.37s\tremaining: 16.9s\n",
      "123:\tlearn: 1.0233721\ttotal: 2.39s\tremaining: 16.9s\n",
      "124:\tlearn: 1.0229688\ttotal: 2.4s\tremaining: 16.8s\n",
      "125:\tlearn: 1.0223253\ttotal: 2.42s\tremaining: 16.8s\n",
      "126:\tlearn: 1.0218578\ttotal: 2.46s\tremaining: 16.9s\n",
      "127:\tlearn: 1.0212831\ttotal: 2.48s\tremaining: 16.9s\n",
      "128:\tlearn: 1.0208050\ttotal: 2.5s\tremaining: 16.9s\n",
      "129:\tlearn: 1.0204011\ttotal: 2.53s\tremaining: 17s\n",
      "130:\tlearn: 1.0200656\ttotal: 2.55s\tremaining: 16.9s\n",
      "131:\tlearn: 1.0197669\ttotal: 2.57s\tremaining: 16.9s\n",
      "132:\tlearn: 1.0194258\ttotal: 2.6s\tremaining: 16.9s\n",
      "133:\tlearn: 1.0187024\ttotal: 2.62s\tremaining: 16.9s\n",
      "134:\tlearn: 1.0183871\ttotal: 2.64s\tremaining: 16.9s\n",
      "135:\tlearn: 1.0179641\ttotal: 2.66s\tremaining: 16.9s\n",
      "136:\tlearn: 1.0174079\ttotal: 2.69s\tremaining: 16.9s\n",
      "137:\tlearn: 1.0169712\ttotal: 2.7s\tremaining: 16.9s\n",
      "138:\tlearn: 1.0164373\ttotal: 2.72s\tremaining: 16.9s\n",
      "139:\tlearn: 1.0159761\ttotal: 2.75s\tremaining: 16.9s\n",
      "140:\tlearn: 1.0155727\ttotal: 2.77s\tremaining: 16.9s\n",
      "141:\tlearn: 1.0152128\ttotal: 2.79s\tremaining: 16.9s\n",
      "142:\tlearn: 1.0147739\ttotal: 2.83s\tremaining: 16.9s\n",
      "143:\tlearn: 1.0145178\ttotal: 2.84s\tremaining: 16.9s\n",
      "144:\tlearn: 1.0140177\ttotal: 2.86s\tremaining: 16.9s\n",
      "145:\tlearn: 1.0136186\ttotal: 2.87s\tremaining: 16.8s\n",
      "146:\tlearn: 1.0134423\ttotal: 2.89s\tremaining: 16.8s\n",
      "147:\tlearn: 1.0131398\ttotal: 2.9s\tremaining: 16.7s\n",
      "148:\tlearn: 1.0127123\ttotal: 2.92s\tremaining: 16.7s\n",
      "149:\tlearn: 1.0124158\ttotal: 2.94s\tremaining: 16.7s\n",
      "150:\tlearn: 1.0121174\ttotal: 2.96s\tremaining: 16.6s\n",
      "151:\tlearn: 1.0117722\ttotal: 2.98s\tremaining: 16.6s\n",
      "152:\tlearn: 1.0114670\ttotal: 2.99s\tremaining: 16.5s\n",
      "153:\tlearn: 1.0111150\ttotal: 3s\tremaining: 16.5s\n",
      "154:\tlearn: 1.0107218\ttotal: 3.02s\tremaining: 16.5s\n",
      "155:\tlearn: 1.0104218\ttotal: 3.03s\tremaining: 16.4s\n",
      "156:\tlearn: 1.0101011\ttotal: 3.05s\tremaining: 16.4s\n",
      "157:\tlearn: 1.0098626\ttotal: 3.06s\tremaining: 16.3s\n",
      "158:\tlearn: 1.0095482\ttotal: 3.08s\tremaining: 16.3s\n",
      "159:\tlearn: 1.0092798\ttotal: 3.1s\tremaining: 16.2s\n",
      "160:\tlearn: 1.0088720\ttotal: 3.11s\tremaining: 16.2s\n",
      "161:\tlearn: 1.0085107\ttotal: 3.13s\tremaining: 16.2s\n",
      "162:\tlearn: 1.0081722\ttotal: 3.15s\tremaining: 16.2s\n",
      "163:\tlearn: 1.0079015\ttotal: 3.16s\tremaining: 16.1s\n",
      "164:\tlearn: 1.0073564\ttotal: 3.18s\tremaining: 16.1s\n",
      "165:\tlearn: 1.0071411\ttotal: 3.19s\tremaining: 16.1s\n",
      "166:\tlearn: 1.0068300\ttotal: 3.21s\tremaining: 16s\n",
      "167:\tlearn: 1.0065635\ttotal: 3.23s\tremaining: 16s\n",
      "168:\tlearn: 1.0062879\ttotal: 3.24s\tremaining: 15.9s\n",
      "169:\tlearn: 1.0060509\ttotal: 3.26s\tremaining: 15.9s\n",
      "170:\tlearn: 1.0055259\ttotal: 3.27s\tremaining: 15.9s\n",
      "171:\tlearn: 1.0052532\ttotal: 3.29s\tremaining: 15.8s\n",
      "172:\tlearn: 1.0045222\ttotal: 3.3s\tremaining: 15.8s\n",
      "173:\tlearn: 1.0041487\ttotal: 3.32s\tremaining: 15.8s\n",
      "174:\tlearn: 1.0039268\ttotal: 3.34s\tremaining: 15.7s\n",
      "175:\tlearn: 1.0035165\ttotal: 3.35s\tremaining: 15.7s\n",
      "176:\tlearn: 1.0032378\ttotal: 3.37s\tremaining: 15.7s\n",
      "177:\tlearn: 1.0029769\ttotal: 3.38s\tremaining: 15.6s\n",
      "178:\tlearn: 1.0026818\ttotal: 3.4s\tremaining: 15.6s\n",
      "179:\tlearn: 1.0024792\ttotal: 3.41s\tremaining: 15.6s\n",
      "180:\tlearn: 1.0020114\ttotal: 3.43s\tremaining: 15.5s\n",
      "181:\tlearn: 1.0017635\ttotal: 3.45s\tremaining: 15.5s\n",
      "182:\tlearn: 1.0015350\ttotal: 3.47s\tremaining: 15.5s\n",
      "183:\tlearn: 1.0012823\ttotal: 3.5s\tremaining: 15.5s\n",
      "184:\tlearn: 1.0009073\ttotal: 3.52s\tremaining: 15.5s\n",
      "185:\tlearn: 1.0007310\ttotal: 3.53s\tremaining: 15.5s\n",
      "186:\tlearn: 1.0005309\ttotal: 3.55s\tremaining: 15.4s\n",
      "187:\tlearn: 1.0002332\ttotal: 3.56s\tremaining: 15.4s\n",
      "188:\tlearn: 0.9998209\ttotal: 3.58s\tremaining: 15.3s\n",
      "189:\tlearn: 0.9996382\ttotal: 3.59s\tremaining: 15.3s\n",
      "190:\tlearn: 0.9993952\ttotal: 3.61s\tremaining: 15.3s\n",
      "191:\tlearn: 0.9991413\ttotal: 3.62s\tremaining: 15.2s\n",
      "192:\tlearn: 0.9989562\ttotal: 3.64s\tremaining: 15.2s\n",
      "193:\tlearn: 0.9987445\ttotal: 3.66s\tremaining: 15.2s\n",
      "194:\tlearn: 0.9984081\ttotal: 3.67s\tremaining: 15.2s\n",
      "195:\tlearn: 0.9981325\ttotal: 3.69s\tremaining: 15.2s\n",
      "196:\tlearn: 0.9979807\ttotal: 3.71s\tremaining: 15.1s\n",
      "197:\tlearn: 0.9974094\ttotal: 3.73s\tremaining: 15.1s\n",
      "198:\tlearn: 0.9969739\ttotal: 3.74s\tremaining: 15.1s\n",
      "199:\tlearn: 0.9964920\ttotal: 3.76s\tremaining: 15s\n",
      "200:\tlearn: 0.9962964\ttotal: 3.77s\tremaining: 15s\n",
      "201:\tlearn: 0.9961466\ttotal: 3.79s\tremaining: 15s\n",
      "202:\tlearn: 0.9959459\ttotal: 3.8s\tremaining: 14.9s\n",
      "203:\tlearn: 0.9955900\ttotal: 3.83s\tremaining: 14.9s\n",
      "204:\tlearn: 0.9954283\ttotal: 3.86s\tremaining: 15s\n",
      "205:\tlearn: 0.9952364\ttotal: 3.88s\tremaining: 15s\n",
      "206:\tlearn: 0.9950936\ttotal: 3.91s\tremaining: 15s\n",
      "207:\tlearn: 0.9948631\ttotal: 3.94s\tremaining: 15s\n",
      "208:\tlearn: 0.9946682\ttotal: 3.96s\tremaining: 15s\n",
      "209:\tlearn: 0.9945605\ttotal: 3.99s\tremaining: 15s\n",
      "210:\tlearn: 0.9944758\ttotal: 4.01s\tremaining: 15s\n",
      "211:\tlearn: 0.9942097\ttotal: 4.03s\tremaining: 15s\n",
      "212:\tlearn: 0.9939466\ttotal: 4.05s\tremaining: 15s\n",
      "213:\tlearn: 0.9937415\ttotal: 4.07s\tremaining: 15s\n",
      "214:\tlearn: 0.9934304\ttotal: 4.1s\tremaining: 15s\n",
      "215:\tlearn: 0.9932181\ttotal: 4.12s\tremaining: 14.9s\n",
      "216:\tlearn: 0.9930842\ttotal: 4.14s\tremaining: 14.9s\n",
      "217:\tlearn: 0.9928598\ttotal: 4.16s\tremaining: 14.9s\n",
      "218:\tlearn: 0.9926602\ttotal: 4.17s\tremaining: 14.9s\n",
      "219:\tlearn: 0.9924145\ttotal: 4.19s\tremaining: 14.9s\n",
      "220:\tlearn: 0.9922195\ttotal: 4.2s\tremaining: 14.8s\n",
      "221:\tlearn: 0.9920268\ttotal: 4.22s\tremaining: 14.8s\n",
      "222:\tlearn: 0.9917206\ttotal: 4.24s\tremaining: 14.8s\n",
      "223:\tlearn: 0.9914465\ttotal: 4.26s\tremaining: 14.8s\n",
      "224:\tlearn: 0.9911533\ttotal: 4.27s\tremaining: 14.7s\n",
      "225:\tlearn: 0.9906598\ttotal: 4.29s\tremaining: 14.7s\n",
      "226:\tlearn: 0.9903035\ttotal: 4.3s\tremaining: 14.7s\n",
      "227:\tlearn: 0.9900147\ttotal: 4.32s\tremaining: 14.6s\n",
      "228:\tlearn: 0.9897213\ttotal: 4.33s\tremaining: 14.6s\n",
      "229:\tlearn: 0.9894856\ttotal: 4.34s\tremaining: 14.5s\n",
      "230:\tlearn: 0.9894215\ttotal: 4.36s\tremaining: 14.5s\n",
      "231:\tlearn: 0.9891477\ttotal: 4.37s\tremaining: 14.5s\n",
      "232:\tlearn: 0.9889682\ttotal: 4.39s\tremaining: 14.5s\n",
      "233:\tlearn: 0.9888261\ttotal: 4.41s\tremaining: 14.4s\n",
      "234:\tlearn: 0.9886423\ttotal: 4.43s\tremaining: 14.4s\n",
      "235:\tlearn: 0.9884693\ttotal: 4.45s\tremaining: 14.4s\n",
      "236:\tlearn: 0.9884052\ttotal: 4.46s\tremaining: 14.4s\n",
      "237:\tlearn: 0.9882892\ttotal: 4.48s\tremaining: 14.3s\n",
      "238:\tlearn: 0.9880609\ttotal: 4.49s\tremaining: 14.3s\n",
      "239:\tlearn: 0.9878670\ttotal: 4.5s\tremaining: 14.3s\n",
      "240:\tlearn: 0.9876264\ttotal: 4.52s\tremaining: 14.2s\n",
      "241:\tlearn: 0.9873071\ttotal: 4.54s\tremaining: 14.2s\n",
      "242:\tlearn: 0.9871092\ttotal: 4.55s\tremaining: 14.2s\n",
      "243:\tlearn: 0.9867321\ttotal: 4.57s\tremaining: 14.2s\n",
      "244:\tlearn: 0.9864769\ttotal: 4.59s\tremaining: 14.2s\n",
      "245:\tlearn: 0.9863510\ttotal: 4.61s\tremaining: 14.1s\n",
      "246:\tlearn: 0.9861489\ttotal: 4.62s\tremaining: 14.1s\n",
      "247:\tlearn: 0.9859249\ttotal: 4.64s\tremaining: 14.1s\n",
      "248:\tlearn: 0.9857518\ttotal: 4.65s\tremaining: 14s\n",
      "249:\tlearn: 0.9855331\ttotal: 4.67s\tremaining: 14s\n",
      "250:\tlearn: 0.9851827\ttotal: 4.69s\tremaining: 14s\n",
      "251:\tlearn: 0.9849929\ttotal: 4.7s\tremaining: 14s\n",
      "252:\tlearn: 0.9847898\ttotal: 4.72s\tremaining: 13.9s\n",
      "253:\tlearn: 0.9846855\ttotal: 4.74s\tremaining: 13.9s\n",
      "254:\tlearn: 0.9844248\ttotal: 4.76s\tremaining: 13.9s\n",
      "255:\tlearn: 0.9842636\ttotal: 4.78s\tremaining: 13.9s\n",
      "256:\tlearn: 0.9839827\ttotal: 4.79s\tremaining: 13.9s\n",
      "257:\tlearn: 0.9835753\ttotal: 4.81s\tremaining: 13.8s\n",
      "258:\tlearn: 0.9834376\ttotal: 4.83s\tremaining: 13.8s\n",
      "259:\tlearn: 0.9832738\ttotal: 4.84s\tremaining: 13.8s\n",
      "260:\tlearn: 0.9830781\ttotal: 4.86s\tremaining: 13.8s\n",
      "261:\tlearn: 0.9829762\ttotal: 4.88s\tremaining: 13.7s\n",
      "262:\tlearn: 0.9825411\ttotal: 4.91s\tremaining: 13.7s\n",
      "263:\tlearn: 0.9823722\ttotal: 4.92s\tremaining: 13.7s\n",
      "264:\tlearn: 0.9820945\ttotal: 4.94s\tremaining: 13.7s\n",
      "265:\tlearn: 0.9818801\ttotal: 4.96s\tremaining: 13.7s\n",
      "266:\tlearn: 0.9817933\ttotal: 4.98s\tremaining: 13.7s\n",
      "267:\tlearn: 0.9816207\ttotal: 5s\tremaining: 13.7s\n",
      "268:\tlearn: 0.9814917\ttotal: 5.03s\tremaining: 13.7s\n",
      "269:\tlearn: 0.9813157\ttotal: 5.05s\tremaining: 13.6s\n",
      "270:\tlearn: 0.9810276\ttotal: 5.06s\tremaining: 13.6s\n",
      "271:\tlearn: 0.9807727\ttotal: 5.08s\tremaining: 13.6s\n",
      "272:\tlearn: 0.9806205\ttotal: 5.09s\tremaining: 13.6s\n",
      "273:\tlearn: 0.9803745\ttotal: 5.11s\tremaining: 13.5s\n",
      "274:\tlearn: 0.9801011\ttotal: 5.12s\tremaining: 13.5s\n",
      "275:\tlearn: 0.9799406\ttotal: 5.13s\tremaining: 13.5s\n",
      "276:\tlearn: 0.9796941\ttotal: 5.14s\tremaining: 13.4s\n",
      "277:\tlearn: 0.9794722\ttotal: 5.16s\tremaining: 13.4s\n",
      "278:\tlearn: 0.9793328\ttotal: 5.17s\tremaining: 13.4s\n",
      "279:\tlearn: 0.9791554\ttotal: 5.19s\tremaining: 13.3s\n",
      "280:\tlearn: 0.9789708\ttotal: 5.2s\tremaining: 13.3s\n",
      "281:\tlearn: 0.9788290\ttotal: 5.21s\tremaining: 13.3s\n",
      "282:\tlearn: 0.9786875\ttotal: 5.22s\tremaining: 13.2s\n",
      "283:\tlearn: 0.9784717\ttotal: 5.24s\tremaining: 13.2s\n",
      "284:\tlearn: 0.9783692\ttotal: 5.25s\tremaining: 13.2s\n",
      "285:\tlearn: 0.9781302\ttotal: 5.26s\tremaining: 13.1s\n",
      "286:\tlearn: 0.9780110\ttotal: 5.28s\tremaining: 13.1s\n",
      "287:\tlearn: 0.9778365\ttotal: 5.29s\tremaining: 13.1s\n",
      "288:\tlearn: 0.9776993\ttotal: 5.3s\tremaining: 13s\n",
      "289:\tlearn: 0.9774961\ttotal: 5.31s\tremaining: 13s\n",
      "290:\tlearn: 0.9773722\ttotal: 5.33s\tremaining: 13s\n",
      "291:\tlearn: 0.9772398\ttotal: 5.34s\tremaining: 12.9s\n",
      "292:\tlearn: 0.9771540\ttotal: 5.35s\tremaining: 12.9s\n",
      "293:\tlearn: 0.9770171\ttotal: 5.37s\tremaining: 12.9s\n",
      "294:\tlearn: 0.9769057\ttotal: 5.38s\tremaining: 12.9s\n",
      "295:\tlearn: 0.9768410\ttotal: 5.39s\tremaining: 12.8s\n",
      "296:\tlearn: 0.9766275\ttotal: 5.4s\tremaining: 12.8s\n",
      "297:\tlearn: 0.9763973\ttotal: 5.42s\tremaining: 12.8s\n",
      "298:\tlearn: 0.9762340\ttotal: 5.43s\tremaining: 12.7s\n",
      "299:\tlearn: 0.9759990\ttotal: 5.44s\tremaining: 12.7s\n",
      "300:\tlearn: 0.9759142\ttotal: 5.46s\tremaining: 12.7s\n",
      "301:\tlearn: 0.9756604\ttotal: 5.47s\tremaining: 12.6s\n",
      "302:\tlearn: 0.9754409\ttotal: 5.49s\tremaining: 12.6s\n",
      "303:\tlearn: 0.9752323\ttotal: 5.5s\tremaining: 12.6s\n",
      "304:\tlearn: 0.9750549\ttotal: 5.52s\tremaining: 12.6s\n",
      "305:\tlearn: 0.9749063\ttotal: 5.53s\tremaining: 12.5s\n",
      "306:\tlearn: 0.9747911\ttotal: 5.55s\tremaining: 12.5s\n",
      "307:\tlearn: 0.9745175\ttotal: 5.56s\tremaining: 12.5s\n",
      "308:\tlearn: 0.9743502\ttotal: 5.58s\tremaining: 12.5s\n",
      "309:\tlearn: 0.9741462\ttotal: 5.61s\tremaining: 12.5s\n",
      "310:\tlearn: 0.9739527\ttotal: 5.62s\tremaining: 12.5s\n",
      "311:\tlearn: 0.9738667\ttotal: 5.63s\tremaining: 12.4s\n",
      "312:\tlearn: 0.9737669\ttotal: 5.64s\tremaining: 12.4s\n",
      "313:\tlearn: 0.9736568\ttotal: 5.66s\tremaining: 12.4s\n",
      "314:\tlearn: 0.9735136\ttotal: 5.67s\tremaining: 12.3s\n",
      "315:\tlearn: 0.9732885\ttotal: 5.68s\tremaining: 12.3s\n",
      "316:\tlearn: 0.9730967\ttotal: 5.7s\tremaining: 12.3s\n",
      "317:\tlearn: 0.9727383\ttotal: 5.71s\tremaining: 12.3s\n",
      "318:\tlearn: 0.9725413\ttotal: 5.73s\tremaining: 12.2s\n",
      "319:\tlearn: 0.9724258\ttotal: 5.74s\tremaining: 12.2s\n",
      "320:\tlearn: 0.9722396\ttotal: 5.75s\tremaining: 12.2s\n",
      "321:\tlearn: 0.9721674\ttotal: 5.77s\tremaining: 12.1s\n",
      "322:\tlearn: 0.9719858\ttotal: 5.78s\tremaining: 12.1s\n",
      "323:\tlearn: 0.9718200\ttotal: 5.79s\tremaining: 12.1s\n",
      "324:\tlearn: 0.9716979\ttotal: 5.81s\tremaining: 12.1s\n",
      "325:\tlearn: 0.9716134\ttotal: 5.82s\tremaining: 12s\n",
      "326:\tlearn: 0.9713803\ttotal: 5.83s\tremaining: 12s\n",
      "327:\tlearn: 0.9712990\ttotal: 5.85s\tremaining: 12s\n",
      "328:\tlearn: 0.9711305\ttotal: 5.86s\tremaining: 12s\n",
      "329:\tlearn: 0.9710653\ttotal: 5.87s\tremaining: 11.9s\n",
      "330:\tlearn: 0.9709783\ttotal: 5.88s\tremaining: 11.9s\n",
      "331:\tlearn: 0.9709117\ttotal: 5.9s\tremaining: 11.9s\n",
      "332:\tlearn: 0.9708276\ttotal: 5.92s\tremaining: 11.8s\n",
      "333:\tlearn: 0.9706721\ttotal: 5.93s\tremaining: 11.8s\n",
      "334:\tlearn: 0.9705489\ttotal: 5.94s\tremaining: 11.8s\n",
      "335:\tlearn: 0.9703251\ttotal: 5.96s\tremaining: 11.8s\n",
      "336:\tlearn: 0.9702111\ttotal: 5.97s\tremaining: 11.7s\n",
      "337:\tlearn: 0.9699490\ttotal: 5.98s\tremaining: 11.7s\n",
      "338:\tlearn: 0.9697525\ttotal: 6s\tremaining: 11.7s\n",
      "339:\tlearn: 0.9696782\ttotal: 6.01s\tremaining: 11.7s\n",
      "340:\tlearn: 0.9696081\ttotal: 6.03s\tremaining: 11.7s\n",
      "341:\tlearn: 0.9693981\ttotal: 6.04s\tremaining: 11.6s\n",
      "342:\tlearn: 0.9693194\ttotal: 6.06s\tremaining: 11.6s\n",
      "343:\tlearn: 0.9691095\ttotal: 6.08s\tremaining: 11.6s\n",
      "344:\tlearn: 0.9689643\ttotal: 6.1s\tremaining: 11.6s\n",
      "345:\tlearn: 0.9688155\ttotal: 6.12s\tremaining: 11.6s\n",
      "346:\tlearn: 0.9686331\ttotal: 6.14s\tremaining: 11.6s\n",
      "347:\tlearn: 0.9684906\ttotal: 6.16s\tremaining: 11.5s\n",
      "348:\tlearn: 0.9683554\ttotal: 6.18s\tremaining: 11.5s\n",
      "349:\tlearn: 0.9682337\ttotal: 6.2s\tremaining: 11.5s\n",
      "350:\tlearn: 0.9680863\ttotal: 6.22s\tremaining: 11.5s\n",
      "351:\tlearn: 0.9679006\ttotal: 6.24s\tremaining: 11.5s\n",
      "352:\tlearn: 0.9676701\ttotal: 6.26s\tremaining: 11.5s\n",
      "353:\tlearn: 0.9675973\ttotal: 6.28s\tremaining: 11.5s\n",
      "354:\tlearn: 0.9674338\ttotal: 6.3s\tremaining: 11.4s\n",
      "355:\tlearn: 0.9673005\ttotal: 6.31s\tremaining: 11.4s\n",
      "356:\tlearn: 0.9671904\ttotal: 6.33s\tremaining: 11.4s\n",
      "357:\tlearn: 0.9670632\ttotal: 6.35s\tremaining: 11.4s\n",
      "358:\tlearn: 0.9667666\ttotal: 6.37s\tremaining: 11.4s\n",
      "359:\tlearn: 0.9666577\ttotal: 6.39s\tremaining: 11.4s\n",
      "360:\tlearn: 0.9664836\ttotal: 6.41s\tremaining: 11.3s\n",
      "361:\tlearn: 0.9664196\ttotal: 6.43s\tremaining: 11.3s\n",
      "362:\tlearn: 0.9663403\ttotal: 6.45s\tremaining: 11.3s\n",
      "363:\tlearn: 0.9661825\ttotal: 6.47s\tremaining: 11.3s\n",
      "364:\tlearn: 0.9661147\ttotal: 6.49s\tremaining: 11.3s\n",
      "365:\tlearn: 0.9659714\ttotal: 6.51s\tremaining: 11.3s\n",
      "366:\tlearn: 0.9657831\ttotal: 6.54s\tremaining: 11.3s\n",
      "367:\tlearn: 0.9657078\ttotal: 6.56s\tremaining: 11.3s\n",
      "368:\tlearn: 0.9654427\ttotal: 6.58s\tremaining: 11.3s\n",
      "369:\tlearn: 0.9653262\ttotal: 6.6s\tremaining: 11.2s\n",
      "370:\tlearn: 0.9651682\ttotal: 6.63s\tremaining: 11.2s\n",
      "371:\tlearn: 0.9650474\ttotal: 6.64s\tremaining: 11.2s\n",
      "372:\tlearn: 0.9649217\ttotal: 6.66s\tremaining: 11.2s\n",
      "373:\tlearn: 0.9647509\ttotal: 6.68s\tremaining: 11.2s\n",
      "374:\tlearn: 0.9646336\ttotal: 6.69s\tremaining: 11.2s\n",
      "375:\tlearn: 0.9645001\ttotal: 6.71s\tremaining: 11.1s\n",
      "376:\tlearn: 0.9643931\ttotal: 6.72s\tremaining: 11.1s\n",
      "377:\tlearn: 0.9643070\ttotal: 6.74s\tremaining: 11.1s\n",
      "378:\tlearn: 0.9642553\ttotal: 6.75s\tremaining: 11.1s\n",
      "379:\tlearn: 0.9641029\ttotal: 6.76s\tremaining: 11s\n",
      "380:\tlearn: 0.9640084\ttotal: 6.78s\tremaining: 11s\n",
      "381:\tlearn: 0.9638546\ttotal: 6.81s\tremaining: 11s\n",
      "382:\tlearn: 0.9636443\ttotal: 6.83s\tremaining: 11s\n",
      "383:\tlearn: 0.9635445\ttotal: 6.84s\tremaining: 11s\n",
      "384:\tlearn: 0.9634247\ttotal: 6.87s\tremaining: 11s\n",
      "385:\tlearn: 0.9632686\ttotal: 6.88s\tremaining: 11s\n",
      "386:\tlearn: 0.9631228\ttotal: 6.9s\tremaining: 10.9s\n",
      "387:\tlearn: 0.9630283\ttotal: 6.92s\tremaining: 10.9s\n",
      "388:\tlearn: 0.9629416\ttotal: 6.93s\tremaining: 10.9s\n",
      "389:\tlearn: 0.9628432\ttotal: 6.94s\tremaining: 10.9s\n",
      "390:\tlearn: 0.9627438\ttotal: 6.95s\tremaining: 10.8s\n",
      "391:\tlearn: 0.9626628\ttotal: 6.97s\tremaining: 10.8s\n",
      "392:\tlearn: 0.9625399\ttotal: 6.98s\tremaining: 10.8s\n",
      "393:\tlearn: 0.9624896\ttotal: 6.99s\tremaining: 10.8s\n",
      "394:\tlearn: 0.9623361\ttotal: 7.01s\tremaining: 10.7s\n",
      "395:\tlearn: 0.9621694\ttotal: 7.02s\tremaining: 10.7s\n",
      "396:\tlearn: 0.9619460\ttotal: 7.04s\tremaining: 10.7s\n",
      "397:\tlearn: 0.9617932\ttotal: 7.05s\tremaining: 10.7s\n",
      "398:\tlearn: 0.9616863\ttotal: 7.07s\tremaining: 10.6s\n",
      "399:\tlearn: 0.9615994\ttotal: 7.08s\tremaining: 10.6s\n",
      "400:\tlearn: 0.9615446\ttotal: 7.09s\tremaining: 10.6s\n",
      "401:\tlearn: 0.9613616\ttotal: 7.11s\tremaining: 10.6s\n",
      "402:\tlearn: 0.9611725\ttotal: 7.12s\tremaining: 10.5s\n",
      "403:\tlearn: 0.9610283\ttotal: 7.13s\tremaining: 10.5s\n",
      "404:\tlearn: 0.9608020\ttotal: 7.14s\tremaining: 10.5s\n",
      "405:\tlearn: 0.9605729\ttotal: 7.16s\tremaining: 10.5s\n",
      "406:\tlearn: 0.9604753\ttotal: 7.17s\tremaining: 10.5s\n",
      "407:\tlearn: 0.9603291\ttotal: 7.19s\tremaining: 10.4s\n",
      "408:\tlearn: 0.9602260\ttotal: 7.21s\tremaining: 10.4s\n",
      "409:\tlearn: 0.9600686\ttotal: 7.23s\tremaining: 10.4s\n",
      "410:\tlearn: 0.9599792\ttotal: 7.25s\tremaining: 10.4s\n",
      "411:\tlearn: 0.9598440\ttotal: 7.27s\tremaining: 10.4s\n",
      "412:\tlearn: 0.9597995\ttotal: 7.29s\tremaining: 10.4s\n",
      "413:\tlearn: 0.9597542\ttotal: 7.31s\tremaining: 10.3s\n",
      "414:\tlearn: 0.9596415\ttotal: 7.33s\tremaining: 10.3s\n",
      "415:\tlearn: 0.9595597\ttotal: 7.36s\tremaining: 10.3s\n",
      "416:\tlearn: 0.9594591\ttotal: 7.38s\tremaining: 10.3s\n",
      "417:\tlearn: 0.9592828\ttotal: 7.4s\tremaining: 10.3s\n",
      "418:\tlearn: 0.9592290\ttotal: 7.42s\tremaining: 10.3s\n",
      "419:\tlearn: 0.9591669\ttotal: 7.44s\tremaining: 10.3s\n",
      "420:\tlearn: 0.9589794\ttotal: 7.47s\tremaining: 10.3s\n",
      "421:\tlearn: 0.9588479\ttotal: 7.49s\tremaining: 10.3s\n",
      "422:\tlearn: 0.9587457\ttotal: 7.5s\tremaining: 10.2s\n",
      "423:\tlearn: 0.9586414\ttotal: 7.52s\tremaining: 10.2s\n",
      "424:\tlearn: 0.9585339\ttotal: 7.53s\tremaining: 10.2s\n",
      "425:\tlearn: 0.9584534\ttotal: 7.54s\tremaining: 10.2s\n",
      "426:\tlearn: 0.9583885\ttotal: 7.56s\tremaining: 10.1s\n",
      "427:\tlearn: 0.9582486\ttotal: 7.57s\tremaining: 10.1s\n",
      "428:\tlearn: 0.9581471\ttotal: 7.59s\tremaining: 10.1s\n",
      "429:\tlearn: 0.9580076\ttotal: 7.6s\tremaining: 10.1s\n",
      "430:\tlearn: 0.9578823\ttotal: 7.62s\tremaining: 10.1s\n",
      "431:\tlearn: 0.9577484\ttotal: 7.63s\tremaining: 10s\n",
      "432:\tlearn: 0.9576655\ttotal: 7.64s\tremaining: 10s\n",
      "433:\tlearn: 0.9575951\ttotal: 7.66s\tremaining: 9.99s\n",
      "434:\tlearn: 0.9574555\ttotal: 7.67s\tremaining: 9.97s\n",
      "435:\tlearn: 0.9573073\ttotal: 7.69s\tremaining: 9.95s\n",
      "436:\tlearn: 0.9572595\ttotal: 7.7s\tremaining: 9.92s\n",
      "437:\tlearn: 0.9571379\ttotal: 7.71s\tremaining: 9.9s\n",
      "438:\tlearn: 0.9570652\ttotal: 7.73s\tremaining: 9.87s\n",
      "439:\tlearn: 0.9569705\ttotal: 7.74s\tremaining: 9.85s\n",
      "440:\tlearn: 0.9569069\ttotal: 7.75s\tremaining: 9.83s\n",
      "441:\tlearn: 0.9567888\ttotal: 7.77s\tremaining: 9.81s\n",
      "442:\tlearn: 0.9567506\ttotal: 7.79s\tremaining: 9.79s\n",
      "443:\tlearn: 0.9566065\ttotal: 7.8s\tremaining: 9.77s\n",
      "444:\tlearn: 0.9564956\ttotal: 7.81s\tremaining: 9.74s\n",
      "445:\tlearn: 0.9563965\ttotal: 7.82s\tremaining: 9.72s\n",
      "446:\tlearn: 0.9563329\ttotal: 7.84s\tremaining: 9.7s\n",
      "447:\tlearn: 0.9562162\ttotal: 7.85s\tremaining: 9.67s\n",
      "448:\tlearn: 0.9561529\ttotal: 7.86s\tremaining: 9.65s\n",
      "449:\tlearn: 0.9560264\ttotal: 7.88s\tremaining: 9.63s\n",
      "450:\tlearn: 0.9559435\ttotal: 7.89s\tremaining: 9.61s\n",
      "451:\tlearn: 0.9558483\ttotal: 7.91s\tremaining: 9.58s\n",
      "452:\tlearn: 0.9557773\ttotal: 7.92s\tremaining: 9.56s\n",
      "453:\tlearn: 0.9556765\ttotal: 7.93s\tremaining: 9.54s\n",
      "454:\tlearn: 0.9556138\ttotal: 7.95s\tremaining: 9.52s\n",
      "455:\tlearn: 0.9554399\ttotal: 7.97s\tremaining: 9.5s\n",
      "456:\tlearn: 0.9552494\ttotal: 7.98s\tremaining: 9.48s\n",
      "457:\tlearn: 0.9550941\ttotal: 8s\tremaining: 9.46s\n",
      "458:\tlearn: 0.9550068\ttotal: 8.01s\tremaining: 9.44s\n",
      "459:\tlearn: 0.9548856\ttotal: 8.02s\tremaining: 9.42s\n",
      "460:\tlearn: 0.9547794\ttotal: 8.04s\tremaining: 9.4s\n",
      "461:\tlearn: 0.9547194\ttotal: 8.05s\tremaining: 9.38s\n",
      "462:\tlearn: 0.9546236\ttotal: 8.06s\tremaining: 9.35s\n",
      "463:\tlearn: 0.9544886\ttotal: 8.08s\tremaining: 9.33s\n",
      "464:\tlearn: 0.9543139\ttotal: 8.1s\tremaining: 9.32s\n",
      "465:\tlearn: 0.9541777\ttotal: 8.11s\tremaining: 9.3s\n",
      "466:\tlearn: 0.9541017\ttotal: 8.13s\tremaining: 9.28s\n",
      "467:\tlearn: 0.9539226\ttotal: 8.14s\tremaining: 9.26s\n",
      "468:\tlearn: 0.9538461\ttotal: 8.16s\tremaining: 9.23s\n",
      "469:\tlearn: 0.9537270\ttotal: 8.17s\tremaining: 9.21s\n",
      "470:\tlearn: 0.9536819\ttotal: 8.18s\tremaining: 9.19s\n",
      "471:\tlearn: 0.9535281\ttotal: 8.2s\tremaining: 9.17s\n",
      "472:\tlearn: 0.9534489\ttotal: 8.21s\tremaining: 9.15s\n",
      "473:\tlearn: 0.9532550\ttotal: 8.22s\tremaining: 9.13s\n",
      "474:\tlearn: 0.9531448\ttotal: 8.24s\tremaining: 9.1s\n",
      "475:\tlearn: 0.9530962\ttotal: 8.25s\tremaining: 9.08s\n",
      "476:\tlearn: 0.9530334\ttotal: 8.26s\tremaining: 9.06s\n",
      "477:\tlearn: 0.9529177\ttotal: 8.27s\tremaining: 9.04s\n",
      "478:\tlearn: 0.9527978\ttotal: 8.29s\tremaining: 9.02s\n",
      "479:\tlearn: 0.9526929\ttotal: 8.3s\tremaining: 9s\n",
      "480:\tlearn: 0.9526491\ttotal: 8.32s\tremaining: 8.98s\n",
      "481:\tlearn: 0.9525484\ttotal: 8.34s\tremaining: 8.96s\n",
      "482:\tlearn: 0.9524505\ttotal: 8.35s\tremaining: 8.94s\n",
      "483:\tlearn: 0.9523267\ttotal: 8.36s\tremaining: 8.92s\n",
      "484:\tlearn: 0.9522722\ttotal: 8.38s\tremaining: 8.89s\n",
      "485:\tlearn: 0.9521838\ttotal: 8.39s\tremaining: 8.87s\n",
      "486:\tlearn: 0.9519718\ttotal: 8.4s\tremaining: 8.85s\n",
      "487:\tlearn: 0.9518922\ttotal: 8.41s\tremaining: 8.83s\n",
      "488:\tlearn: 0.9517663\ttotal: 8.43s\tremaining: 8.81s\n",
      "489:\tlearn: 0.9516862\ttotal: 8.44s\tremaining: 8.79s\n",
      "490:\tlearn: 0.9515032\ttotal: 8.46s\tremaining: 8.77s\n",
      "491:\tlearn: 0.9514166\ttotal: 8.47s\tremaining: 8.74s\n",
      "492:\tlearn: 0.9512933\ttotal: 8.48s\tremaining: 8.72s\n",
      "493:\tlearn: 0.9511409\ttotal: 8.5s\tremaining: 8.71s\n",
      "494:\tlearn: 0.9510491\ttotal: 8.51s\tremaining: 8.69s\n",
      "495:\tlearn: 0.9509760\ttotal: 8.53s\tremaining: 8.66s\n",
      "496:\tlearn: 0.9508157\ttotal: 8.54s\tremaining: 8.65s\n",
      "497:\tlearn: 0.9507004\ttotal: 8.55s\tremaining: 8.62s\n",
      "498:\tlearn: 0.9505685\ttotal: 8.57s\tremaining: 8.6s\n",
      "499:\tlearn: 0.9504769\ttotal: 8.58s\tremaining: 8.58s\n",
      "500:\tlearn: 0.9503664\ttotal: 8.59s\tremaining: 8.56s\n",
      "501:\tlearn: 0.9502605\ttotal: 8.61s\tremaining: 8.54s\n",
      "502:\tlearn: 0.9501857\ttotal: 8.62s\tremaining: 8.52s\n",
      "503:\tlearn: 0.9501263\ttotal: 8.63s\tremaining: 8.5s\n",
      "504:\tlearn: 0.9500282\ttotal: 8.65s\tremaining: 8.48s\n",
      "505:\tlearn: 0.9499459\ttotal: 8.67s\tremaining: 8.46s\n",
      "506:\tlearn: 0.9498465\ttotal: 8.69s\tremaining: 8.45s\n",
      "507:\tlearn: 0.9497400\ttotal: 8.7s\tremaining: 8.43s\n",
      "508:\tlearn: 0.9496262\ttotal: 8.71s\tremaining: 8.4s\n",
      "509:\tlearn: 0.9495401\ttotal: 8.72s\tremaining: 8.38s\n",
      "510:\tlearn: 0.9494714\ttotal: 8.74s\tremaining: 8.36s\n",
      "511:\tlearn: 0.9493891\ttotal: 8.75s\tremaining: 8.34s\n",
      "512:\tlearn: 0.9492076\ttotal: 8.77s\tremaining: 8.32s\n",
      "513:\tlearn: 0.9490864\ttotal: 8.78s\tremaining: 8.3s\n",
      "514:\tlearn: 0.9489408\ttotal: 8.79s\tremaining: 8.28s\n",
      "515:\tlearn: 0.9488319\ttotal: 8.81s\tremaining: 8.26s\n",
      "516:\tlearn: 0.9487519\ttotal: 8.82s\tremaining: 8.24s\n",
      "517:\tlearn: 0.9486467\ttotal: 8.84s\tremaining: 8.22s\n",
      "518:\tlearn: 0.9485987\ttotal: 8.85s\tremaining: 8.2s\n",
      "519:\tlearn: 0.9485098\ttotal: 8.87s\tremaining: 8.18s\n",
      "520:\tlearn: 0.9484692\ttotal: 8.88s\tremaining: 8.16s\n",
      "521:\tlearn: 0.9484143\ttotal: 8.89s\tremaining: 8.14s\n",
      "522:\tlearn: 0.9483399\ttotal: 8.9s\tremaining: 8.12s\n",
      "523:\tlearn: 0.9482380\ttotal: 8.92s\tremaining: 8.1s\n",
      "524:\tlearn: 0.9481445\ttotal: 8.93s\tremaining: 8.08s\n",
      "525:\tlearn: 0.9480710\ttotal: 8.94s\tremaining: 8.06s\n",
      "526:\tlearn: 0.9480014\ttotal: 8.96s\tremaining: 8.04s\n",
      "527:\tlearn: 0.9478451\ttotal: 8.97s\tremaining: 8.02s\n",
      "528:\tlearn: 0.9477147\ttotal: 8.98s\tremaining: 8s\n",
      "529:\tlearn: 0.9475561\ttotal: 9s\tremaining: 7.98s\n",
      "530:\tlearn: 0.9475132\ttotal: 9.01s\tremaining: 7.96s\n",
      "531:\tlearn: 0.9474316\ttotal: 9.03s\tremaining: 7.94s\n",
      "532:\tlearn: 0.9473237\ttotal: 9.04s\tremaining: 7.92s\n",
      "533:\tlearn: 0.9472422\ttotal: 9.06s\tremaining: 7.9s\n",
      "534:\tlearn: 0.9470239\ttotal: 9.07s\tremaining: 7.88s\n",
      "535:\tlearn: 0.9469761\ttotal: 9.08s\tremaining: 7.86s\n",
      "536:\tlearn: 0.9469222\ttotal: 9.1s\tremaining: 7.84s\n",
      "537:\tlearn: 0.9468437\ttotal: 9.11s\tremaining: 7.82s\n",
      "538:\tlearn: 0.9467703\ttotal: 9.12s\tremaining: 7.8s\n",
      "539:\tlearn: 0.9467304\ttotal: 9.13s\tremaining: 7.78s\n",
      "540:\tlearn: 0.9466238\ttotal: 9.14s\tremaining: 7.76s\n",
      "541:\tlearn: 0.9465584\ttotal: 9.16s\tremaining: 7.74s\n",
      "542:\tlearn: 0.9464587\ttotal: 9.17s\tremaining: 7.72s\n",
      "543:\tlearn: 0.9463606\ttotal: 9.18s\tremaining: 7.7s\n",
      "544:\tlearn: 0.9463090\ttotal: 9.2s\tremaining: 7.68s\n",
      "545:\tlearn: 0.9462630\ttotal: 9.21s\tremaining: 7.66s\n",
      "546:\tlearn: 0.9461600\ttotal: 9.22s\tremaining: 7.64s\n",
      "547:\tlearn: 0.9460962\ttotal: 9.24s\tremaining: 7.62s\n",
      "548:\tlearn: 0.9460175\ttotal: 9.25s\tremaining: 7.6s\n",
      "549:\tlearn: 0.9459707\ttotal: 9.27s\tremaining: 7.58s\n",
      "550:\tlearn: 0.9459451\ttotal: 9.28s\tremaining: 7.56s\n",
      "551:\tlearn: 0.9458880\ttotal: 9.29s\tremaining: 7.54s\n",
      "552:\tlearn: 0.9458503\ttotal: 9.3s\tremaining: 7.52s\n",
      "553:\tlearn: 0.9457074\ttotal: 9.32s\tremaining: 7.5s\n",
      "554:\tlearn: 0.9456005\ttotal: 9.33s\tremaining: 7.48s\n",
      "555:\tlearn: 0.9455105\ttotal: 9.34s\tremaining: 7.46s\n",
      "556:\tlearn: 0.9454416\ttotal: 9.36s\tremaining: 7.44s\n",
      "557:\tlearn: 0.9452846\ttotal: 9.37s\tremaining: 7.42s\n",
      "558:\tlearn: 0.9451682\ttotal: 9.38s\tremaining: 7.4s\n",
      "559:\tlearn: 0.9451269\ttotal: 9.4s\tremaining: 7.38s\n",
      "560:\tlearn: 0.9450730\ttotal: 9.41s\tremaining: 7.36s\n",
      "561:\tlearn: 0.9449654\ttotal: 9.43s\tremaining: 7.35s\n",
      "562:\tlearn: 0.9447911\ttotal: 9.44s\tremaining: 7.33s\n",
      "563:\tlearn: 0.9446721\ttotal: 9.46s\tremaining: 7.31s\n",
      "564:\tlearn: 0.9445439\ttotal: 9.47s\tremaining: 7.29s\n",
      "565:\tlearn: 0.9444937\ttotal: 9.48s\tremaining: 7.27s\n",
      "566:\tlearn: 0.9444053\ttotal: 9.49s\tremaining: 7.25s\n",
      "567:\tlearn: 0.9443445\ttotal: 9.51s\tremaining: 7.23s\n",
      "568:\tlearn: 0.9443056\ttotal: 9.52s\tremaining: 7.21s\n",
      "569:\tlearn: 0.9442186\ttotal: 9.54s\tremaining: 7.19s\n",
      "570:\tlearn: 0.9441773\ttotal: 9.55s\tremaining: 7.17s\n",
      "571:\tlearn: 0.9441204\ttotal: 9.56s\tremaining: 7.16s\n",
      "572:\tlearn: 0.9439984\ttotal: 9.58s\tremaining: 7.14s\n",
      "573:\tlearn: 0.9439313\ttotal: 9.6s\tremaining: 7.13s\n",
      "574:\tlearn: 0.9438386\ttotal: 9.62s\tremaining: 7.11s\n",
      "575:\tlearn: 0.9437519\ttotal: 9.63s\tremaining: 7.09s\n",
      "576:\tlearn: 0.9436869\ttotal: 9.64s\tremaining: 7.07s\n",
      "577:\tlearn: 0.9435793\ttotal: 9.66s\tremaining: 7.05s\n",
      "578:\tlearn: 0.9435200\ttotal: 9.67s\tremaining: 7.03s\n",
      "579:\tlearn: 0.9434749\ttotal: 9.69s\tremaining: 7.01s\n",
      "580:\tlearn: 0.9434329\ttotal: 9.7s\tremaining: 7s\n",
      "581:\tlearn: 0.9432737\ttotal: 9.72s\tremaining: 6.98s\n",
      "582:\tlearn: 0.9431902\ttotal: 9.73s\tremaining: 6.96s\n",
      "583:\tlearn: 0.9430288\ttotal: 9.75s\tremaining: 6.95s\n",
      "584:\tlearn: 0.9429699\ttotal: 9.77s\tremaining: 6.93s\n",
      "585:\tlearn: 0.9427629\ttotal: 9.78s\tremaining: 6.91s\n",
      "586:\tlearn: 0.9426856\ttotal: 9.8s\tremaining: 6.89s\n",
      "587:\tlearn: 0.9425556\ttotal: 9.82s\tremaining: 6.88s\n",
      "588:\tlearn: 0.9424024\ttotal: 9.83s\tremaining: 6.86s\n",
      "589:\tlearn: 0.9423334\ttotal: 9.85s\tremaining: 6.84s\n",
      "590:\tlearn: 0.9421655\ttotal: 9.86s\tremaining: 6.83s\n",
      "591:\tlearn: 0.9421058\ttotal: 9.88s\tremaining: 6.81s\n",
      "592:\tlearn: 0.9420275\ttotal: 9.89s\tremaining: 6.79s\n",
      "593:\tlearn: 0.9419619\ttotal: 9.91s\tremaining: 6.77s\n",
      "594:\tlearn: 0.9419144\ttotal: 9.92s\tremaining: 6.75s\n",
      "595:\tlearn: 0.9418446\ttotal: 9.94s\tremaining: 6.73s\n",
      "596:\tlearn: 0.9417321\ttotal: 9.95s\tremaining: 6.72s\n",
      "597:\tlearn: 0.9416900\ttotal: 9.96s\tremaining: 6.7s\n",
      "598:\tlearn: 0.9416488\ttotal: 9.98s\tremaining: 6.68s\n",
      "599:\tlearn: 0.9415445\ttotal: 9.99s\tremaining: 6.66s\n",
      "600:\tlearn: 0.9414593\ttotal: 10s\tremaining: 6.64s\n",
      "601:\tlearn: 0.9414261\ttotal: 10s\tremaining: 6.63s\n",
      "602:\tlearn: 0.9413220\ttotal: 10s\tremaining: 6.61s\n",
      "603:\tlearn: 0.9412560\ttotal: 10s\tremaining: 6.59s\n",
      "604:\tlearn: 0.9411687\ttotal: 10.1s\tremaining: 6.57s\n",
      "605:\tlearn: 0.9410772\ttotal: 10.1s\tremaining: 6.55s\n",
      "606:\tlearn: 0.9410327\ttotal: 10.1s\tremaining: 6.53s\n",
      "607:\tlearn: 0.9409304\ttotal: 10.1s\tremaining: 6.51s\n",
      "608:\tlearn: 0.9408583\ttotal: 10.1s\tremaining: 6.49s\n",
      "609:\tlearn: 0.9408272\ttotal: 10.1s\tremaining: 6.47s\n",
      "610:\tlearn: 0.9407493\ttotal: 10.1s\tremaining: 6.45s\n",
      "611:\tlearn: 0.9406541\ttotal: 10.2s\tremaining: 6.43s\n",
      "612:\tlearn: 0.9405660\ttotal: 10.2s\tremaining: 6.42s\n",
      "613:\tlearn: 0.9404570\ttotal: 10.2s\tremaining: 6.4s\n",
      "614:\tlearn: 0.9403982\ttotal: 10.2s\tremaining: 6.38s\n",
      "615:\tlearn: 0.9402811\ttotal: 10.2s\tremaining: 6.36s\n",
      "616:\tlearn: 0.9401889\ttotal: 10.2s\tremaining: 6.34s\n",
      "617:\tlearn: 0.9401061\ttotal: 10.2s\tremaining: 6.32s\n",
      "618:\tlearn: 0.9400376\ttotal: 10.2s\tremaining: 6.3s\n",
      "619:\tlearn: 0.9399571\ttotal: 10.3s\tremaining: 6.29s\n",
      "620:\tlearn: 0.9398402\ttotal: 10.3s\tremaining: 6.27s\n",
      "621:\tlearn: 0.9397545\ttotal: 10.3s\tremaining: 6.25s\n",
      "622:\tlearn: 0.9396926\ttotal: 10.3s\tremaining: 6.23s\n",
      "623:\tlearn: 0.9395945\ttotal: 10.3s\tremaining: 6.22s\n",
      "624:\tlearn: 0.9394668\ttotal: 10.3s\tremaining: 6.2s\n",
      "625:\tlearn: 0.9394019\ttotal: 10.3s\tremaining: 6.18s\n",
      "626:\tlearn: 0.9393161\ttotal: 10.4s\tremaining: 6.16s\n",
      "627:\tlearn: 0.9392463\ttotal: 10.4s\tremaining: 6.14s\n",
      "628:\tlearn: 0.9391536\ttotal: 10.4s\tremaining: 6.13s\n",
      "629:\tlearn: 0.9390057\ttotal: 10.4s\tremaining: 6.11s\n",
      "630:\tlearn: 0.9389457\ttotal: 10.4s\tremaining: 6.09s\n",
      "631:\tlearn: 0.9388980\ttotal: 10.4s\tremaining: 6.07s\n",
      "632:\tlearn: 0.9388498\ttotal: 10.4s\tremaining: 6.05s\n",
      "633:\tlearn: 0.9387474\ttotal: 10.5s\tremaining: 6.04s\n",
      "634:\tlearn: 0.9386698\ttotal: 10.5s\tremaining: 6.02s\n",
      "635:\tlearn: 0.9385617\ttotal: 10.5s\tremaining: 6s\n",
      "636:\tlearn: 0.9384875\ttotal: 10.5s\tremaining: 5.98s\n",
      "637:\tlearn: 0.9383774\ttotal: 10.5s\tremaining: 5.97s\n",
      "638:\tlearn: 0.9383100\ttotal: 10.5s\tremaining: 5.95s\n",
      "639:\tlearn: 0.9382223\ttotal: 10.5s\tremaining: 5.93s\n",
      "640:\tlearn: 0.9381629\ttotal: 10.6s\tremaining: 5.91s\n",
      "641:\tlearn: 0.9381346\ttotal: 10.6s\tremaining: 5.89s\n",
      "642:\tlearn: 0.9380958\ttotal: 10.6s\tremaining: 5.87s\n",
      "643:\tlearn: 0.9379361\ttotal: 10.6s\tremaining: 5.86s\n",
      "644:\tlearn: 0.9377689\ttotal: 10.6s\tremaining: 5.84s\n",
      "645:\tlearn: 0.9377158\ttotal: 10.6s\tremaining: 5.82s\n",
      "646:\tlearn: 0.9376477\ttotal: 10.6s\tremaining: 5.8s\n",
      "647:\tlearn: 0.9375635\ttotal: 10.6s\tremaining: 5.78s\n",
      "648:\tlearn: 0.9374161\ttotal: 10.7s\tremaining: 5.77s\n",
      "649:\tlearn: 0.9373564\ttotal: 10.7s\tremaining: 5.75s\n",
      "650:\tlearn: 0.9373011\ttotal: 10.7s\tremaining: 5.73s\n",
      "651:\tlearn: 0.9371991\ttotal: 10.7s\tremaining: 5.72s\n",
      "652:\tlearn: 0.9371018\ttotal: 10.7s\tremaining: 5.7s\n",
      "653:\tlearn: 0.9370030\ttotal: 10.7s\tremaining: 5.68s\n",
      "654:\tlearn: 0.9369157\ttotal: 10.8s\tremaining: 5.67s\n",
      "655:\tlearn: 0.9368037\ttotal: 10.8s\tremaining: 5.65s\n",
      "656:\tlearn: 0.9367479\ttotal: 10.8s\tremaining: 5.63s\n",
      "657:\tlearn: 0.9366527\ttotal: 10.8s\tremaining: 5.62s\n",
      "658:\tlearn: 0.9365093\ttotal: 10.8s\tremaining: 5.6s\n",
      "659:\tlearn: 0.9364811\ttotal: 10.8s\tremaining: 5.58s\n",
      "660:\tlearn: 0.9363404\ttotal: 10.9s\tremaining: 5.57s\n",
      "661:\tlearn: 0.9362877\ttotal: 10.9s\tremaining: 5.55s\n",
      "662:\tlearn: 0.9362318\ttotal: 10.9s\tremaining: 5.54s\n",
      "663:\tlearn: 0.9360914\ttotal: 10.9s\tremaining: 5.52s\n",
      "664:\tlearn: 0.9360400\ttotal: 10.9s\tremaining: 5.5s\n",
      "665:\tlearn: 0.9359728\ttotal: 10.9s\tremaining: 5.49s\n",
      "666:\tlearn: 0.9359098\ttotal: 11s\tremaining: 5.47s\n",
      "667:\tlearn: 0.9358527\ttotal: 11s\tremaining: 5.45s\n",
      "668:\tlearn: 0.9357860\ttotal: 11s\tremaining: 5.44s\n",
      "669:\tlearn: 0.9355921\ttotal: 11s\tremaining: 5.42s\n",
      "670:\tlearn: 0.9355669\ttotal: 11s\tremaining: 5.41s\n",
      "671:\tlearn: 0.9355004\ttotal: 11s\tremaining: 5.39s\n",
      "672:\tlearn: 0.9354692\ttotal: 11.1s\tremaining: 5.38s\n",
      "673:\tlearn: 0.9353386\ttotal: 11.1s\tremaining: 5.36s\n",
      "674:\tlearn: 0.9352459\ttotal: 11.1s\tremaining: 5.35s\n",
      "675:\tlearn: 0.9351895\ttotal: 11.1s\tremaining: 5.33s\n",
      "676:\tlearn: 0.9351211\ttotal: 11.1s\tremaining: 5.32s\n",
      "677:\tlearn: 0.9350499\ttotal: 11.2s\tremaining: 5.3s\n",
      "678:\tlearn: 0.9350149\ttotal: 11.2s\tremaining: 5.29s\n",
      "679:\tlearn: 0.9349627\ttotal: 11.2s\tremaining: 5.28s\n",
      "680:\tlearn: 0.9349268\ttotal: 11.2s\tremaining: 5.26s\n",
      "681:\tlearn: 0.9348721\ttotal: 11.3s\tremaining: 5.25s\n",
      "682:\tlearn: 0.9347961\ttotal: 11.3s\tremaining: 5.24s\n",
      "683:\tlearn: 0.9347222\ttotal: 11.3s\tremaining: 5.22s\n",
      "684:\tlearn: 0.9346899\ttotal: 11.3s\tremaining: 5.21s\n",
      "685:\tlearn: 0.9346177\ttotal: 11.3s\tremaining: 5.19s\n",
      "686:\tlearn: 0.9345009\ttotal: 11.4s\tremaining: 5.18s\n",
      "687:\tlearn: 0.9344697\ttotal: 11.4s\tremaining: 5.16s\n",
      "688:\tlearn: 0.9343923\ttotal: 11.4s\tremaining: 5.15s\n",
      "689:\tlearn: 0.9343193\ttotal: 11.4s\tremaining: 5.14s\n",
      "690:\tlearn: 0.9342745\ttotal: 11.5s\tremaining: 5.12s\n",
      "691:\tlearn: 0.9341929\ttotal: 11.5s\tremaining: 5.11s\n",
      "692:\tlearn: 0.9341160\ttotal: 11.5s\tremaining: 5.09s\n",
      "693:\tlearn: 0.9340589\ttotal: 11.5s\tremaining: 5.08s\n",
      "694:\tlearn: 0.9339912\ttotal: 11.5s\tremaining: 5.06s\n",
      "695:\tlearn: 0.9338745\ttotal: 11.6s\tremaining: 5.05s\n",
      "696:\tlearn: 0.9337962\ttotal: 11.6s\tremaining: 5.03s\n",
      "697:\tlearn: 0.9337496\ttotal: 11.6s\tremaining: 5.02s\n",
      "698:\tlearn: 0.9336930\ttotal: 11.6s\tremaining: 5.01s\n",
      "699:\tlearn: 0.9336051\ttotal: 11.7s\tremaining: 5s\n",
      "700:\tlearn: 0.9335088\ttotal: 11.7s\tremaining: 4.98s\n",
      "701:\tlearn: 0.9334498\ttotal: 11.7s\tremaining: 4.97s\n",
      "702:\tlearn: 0.9333824\ttotal: 11.7s\tremaining: 4.95s\n",
      "703:\tlearn: 0.9333341\ttotal: 11.7s\tremaining: 4.94s\n",
      "704:\tlearn: 0.9331983\ttotal: 11.8s\tremaining: 4.92s\n",
      "705:\tlearn: 0.9331219\ttotal: 11.8s\tremaining: 4.91s\n",
      "706:\tlearn: 0.9329938\ttotal: 11.8s\tremaining: 4.9s\n",
      "707:\tlearn: 0.9328788\ttotal: 11.8s\tremaining: 4.88s\n",
      "708:\tlearn: 0.9328349\ttotal: 11.9s\tremaining: 4.87s\n",
      "709:\tlearn: 0.9327348\ttotal: 11.9s\tremaining: 4.86s\n",
      "710:\tlearn: 0.9326369\ttotal: 11.9s\tremaining: 4.84s\n",
      "711:\tlearn: 0.9326116\ttotal: 11.9s\tremaining: 4.83s\n",
      "712:\tlearn: 0.9325509\ttotal: 12s\tremaining: 4.81s\n",
      "713:\tlearn: 0.9325160\ttotal: 12s\tremaining: 4.8s\n",
      "714:\tlearn: 0.9324575\ttotal: 12s\tremaining: 4.78s\n",
      "715:\tlearn: 0.9323599\ttotal: 12s\tremaining: 4.77s\n",
      "716:\tlearn: 0.9322874\ttotal: 12s\tremaining: 4.75s\n",
      "717:\tlearn: 0.9321995\ttotal: 12.1s\tremaining: 4.74s\n",
      "718:\tlearn: 0.9321436\ttotal: 12.1s\tremaining: 4.72s\n",
      "719:\tlearn: 0.9320137\ttotal: 12.1s\tremaining: 4.71s\n",
      "720:\tlearn: 0.9319943\ttotal: 12.1s\tremaining: 4.69s\n",
      "721:\tlearn: 0.9319617\ttotal: 12.1s\tremaining: 4.68s\n",
      "722:\tlearn: 0.9319219\ttotal: 12.2s\tremaining: 4.66s\n",
      "723:\tlearn: 0.9318273\ttotal: 12.2s\tremaining: 4.65s\n",
      "724:\tlearn: 0.9317211\ttotal: 12.2s\tremaining: 4.63s\n",
      "725:\tlearn: 0.9316336\ttotal: 12.2s\tremaining: 4.62s\n",
      "726:\tlearn: 0.9315460\ttotal: 12.3s\tremaining: 4.6s\n",
      "727:\tlearn: 0.9314664\ttotal: 12.3s\tremaining: 4.59s\n",
      "728:\tlearn: 0.9313806\ttotal: 12.3s\tremaining: 4.58s\n",
      "729:\tlearn: 0.9313088\ttotal: 12.3s\tremaining: 4.56s\n",
      "730:\tlearn: 0.9312426\ttotal: 12.4s\tremaining: 4.55s\n",
      "731:\tlearn: 0.9311820\ttotal: 12.4s\tremaining: 4.54s\n",
      "732:\tlearn: 0.9311052\ttotal: 12.4s\tremaining: 4.52s\n",
      "733:\tlearn: 0.9310673\ttotal: 12.4s\tremaining: 4.51s\n",
      "734:\tlearn: 0.9310042\ttotal: 12.5s\tremaining: 4.49s\n",
      "735:\tlearn: 0.9309189\ttotal: 12.5s\tremaining: 4.48s\n",
      "736:\tlearn: 0.9307506\ttotal: 12.5s\tremaining: 4.46s\n",
      "737:\tlearn: 0.9306851\ttotal: 12.5s\tremaining: 4.45s\n",
      "738:\tlearn: 0.9306441\ttotal: 12.5s\tremaining: 4.43s\n",
      "739:\tlearn: 0.9305096\ttotal: 12.6s\tremaining: 4.42s\n",
      "740:\tlearn: 0.9304332\ttotal: 12.6s\tremaining: 4.4s\n",
      "741:\tlearn: 0.9303393\ttotal: 12.6s\tremaining: 4.39s\n",
      "742:\tlearn: 0.9302492\ttotal: 12.7s\tremaining: 4.38s\n",
      "743:\tlearn: 0.9301638\ttotal: 12.7s\tremaining: 4.37s\n",
      "744:\tlearn: 0.9301223\ttotal: 12.7s\tremaining: 4.36s\n",
      "745:\tlearn: 0.9301010\ttotal: 12.8s\tremaining: 4.35s\n",
      "746:\tlearn: 0.9300284\ttotal: 12.8s\tremaining: 4.33s\n",
      "747:\tlearn: 0.9299245\ttotal: 12.8s\tremaining: 4.32s\n",
      "748:\tlearn: 0.9298939\ttotal: 12.8s\tremaining: 4.3s\n",
      "749:\tlearn: 0.9298450\ttotal: 12.9s\tremaining: 4.29s\n",
      "750:\tlearn: 0.9297723\ttotal: 12.9s\tremaining: 4.27s\n",
      "751:\tlearn: 0.9296999\ttotal: 12.9s\tremaining: 4.26s\n",
      "752:\tlearn: 0.9296247\ttotal: 12.9s\tremaining: 4.25s\n",
      "753:\tlearn: 0.9295591\ttotal: 13s\tremaining: 4.23s\n",
      "754:\tlearn: 0.9295176\ttotal: 13s\tremaining: 4.22s\n",
      "755:\tlearn: 0.9294639\ttotal: 13s\tremaining: 4.2s\n",
      "756:\tlearn: 0.9294014\ttotal: 13s\tremaining: 4.19s\n",
      "757:\tlearn: 0.9293471\ttotal: 13.1s\tremaining: 4.17s\n",
      "758:\tlearn: 0.9292631\ttotal: 13.1s\tremaining: 4.16s\n",
      "759:\tlearn: 0.9291999\ttotal: 13.1s\tremaining: 4.14s\n",
      "760:\tlearn: 0.9291399\ttotal: 13.1s\tremaining: 4.13s\n",
      "761:\tlearn: 0.9290780\ttotal: 13.2s\tremaining: 4.11s\n",
      "762:\tlearn: 0.9290336\ttotal: 13.2s\tremaining: 4.1s\n",
      "763:\tlearn: 0.9289807\ttotal: 13.2s\tremaining: 4.08s\n",
      "764:\tlearn: 0.9289369\ttotal: 13.2s\tremaining: 4.07s\n",
      "765:\tlearn: 0.9288438\ttotal: 13.3s\tremaining: 4.05s\n",
      "766:\tlearn: 0.9287078\ttotal: 13.3s\tremaining: 4.04s\n",
      "767:\tlearn: 0.9286375\ttotal: 13.3s\tremaining: 4.03s\n",
      "768:\tlearn: 0.9285593\ttotal: 13.4s\tremaining: 4.02s\n",
      "769:\tlearn: 0.9284915\ttotal: 13.4s\tremaining: 4s\n",
      "770:\tlearn: 0.9284208\ttotal: 13.4s\tremaining: 3.99s\n",
      "771:\tlearn: 0.9283486\ttotal: 13.5s\tremaining: 3.98s\n",
      "772:\tlearn: 0.9283068\ttotal: 13.5s\tremaining: 3.96s\n",
      "773:\tlearn: 0.9282133\ttotal: 13.5s\tremaining: 3.95s\n",
      "774:\tlearn: 0.9281609\ttotal: 13.5s\tremaining: 3.93s\n",
      "775:\tlearn: 0.9281274\ttotal: 13.6s\tremaining: 3.92s\n",
      "776:\tlearn: 0.9280622\ttotal: 13.6s\tremaining: 3.9s\n",
      "777:\tlearn: 0.9279649\ttotal: 13.6s\tremaining: 3.88s\n",
      "778:\tlearn: 0.9279168\ttotal: 13.6s\tremaining: 3.87s\n",
      "779:\tlearn: 0.9278531\ttotal: 13.7s\tremaining: 3.85s\n",
      "780:\tlearn: 0.9277449\ttotal: 13.7s\tremaining: 3.83s\n",
      "781:\tlearn: 0.9276822\ttotal: 13.7s\tremaining: 3.82s\n",
      "782:\tlearn: 0.9276356\ttotal: 13.7s\tremaining: 3.8s\n",
      "783:\tlearn: 0.9275872\ttotal: 13.7s\tremaining: 3.78s\n",
      "784:\tlearn: 0.9275378\ttotal: 13.8s\tremaining: 3.77s\n",
      "785:\tlearn: 0.9274926\ttotal: 13.8s\tremaining: 3.75s\n",
      "786:\tlearn: 0.9274476\ttotal: 13.8s\tremaining: 3.73s\n",
      "787:\tlearn: 0.9273523\ttotal: 13.8s\tremaining: 3.71s\n",
      "788:\tlearn: 0.9272716\ttotal: 13.8s\tremaining: 3.7s\n",
      "789:\tlearn: 0.9271603\ttotal: 13.8s\tremaining: 3.68s\n",
      "790:\tlearn: 0.9271125\ttotal: 13.9s\tremaining: 3.66s\n",
      "791:\tlearn: 0.9270061\ttotal: 13.9s\tremaining: 3.65s\n",
      "792:\tlearn: 0.9269243\ttotal: 13.9s\tremaining: 3.63s\n",
      "793:\tlearn: 0.9267881\ttotal: 13.9s\tremaining: 3.61s\n",
      "794:\tlearn: 0.9266889\ttotal: 13.9s\tremaining: 3.59s\n",
      "795:\tlearn: 0.9266467\ttotal: 14s\tremaining: 3.58s\n",
      "796:\tlearn: 0.9265379\ttotal: 14s\tremaining: 3.56s\n",
      "797:\tlearn: 0.9264927\ttotal: 14s\tremaining: 3.54s\n",
      "798:\tlearn: 0.9264199\ttotal: 14s\tremaining: 3.52s\n",
      "799:\tlearn: 0.9263412\ttotal: 14s\tremaining: 3.51s\n",
      "800:\tlearn: 0.9262960\ttotal: 14.1s\tremaining: 3.49s\n",
      "801:\tlearn: 0.9262453\ttotal: 14.1s\tremaining: 3.48s\n",
      "802:\tlearn: 0.9261928\ttotal: 14.1s\tremaining: 3.46s\n",
      "803:\tlearn: 0.9261274\ttotal: 14.1s\tremaining: 3.44s\n",
      "804:\tlearn: 0.9260425\ttotal: 14.1s\tremaining: 3.42s\n",
      "805:\tlearn: 0.9259823\ttotal: 14.2s\tremaining: 3.41s\n",
      "806:\tlearn: 0.9259164\ttotal: 14.2s\tremaining: 3.39s\n",
      "807:\tlearn: 0.9258422\ttotal: 14.2s\tremaining: 3.37s\n",
      "808:\tlearn: 0.9258010\ttotal: 14.2s\tremaining: 3.36s\n",
      "809:\tlearn: 0.9256877\ttotal: 14.2s\tremaining: 3.34s\n",
      "810:\tlearn: 0.9256196\ttotal: 14.3s\tremaining: 3.32s\n",
      "811:\tlearn: 0.9255680\ttotal: 14.3s\tremaining: 3.31s\n",
      "812:\tlearn: 0.9255038\ttotal: 14.3s\tremaining: 3.29s\n",
      "813:\tlearn: 0.9254582\ttotal: 14.3s\tremaining: 3.27s\n",
      "814:\tlearn: 0.9254171\ttotal: 14.3s\tremaining: 3.25s\n",
      "815:\tlearn: 0.9253784\ttotal: 14.4s\tremaining: 3.24s\n",
      "816:\tlearn: 0.9252895\ttotal: 14.4s\tremaining: 3.22s\n",
      "817:\tlearn: 0.9251959\ttotal: 14.4s\tremaining: 3.2s\n",
      "818:\tlearn: 0.9251252\ttotal: 14.4s\tremaining: 3.19s\n",
      "819:\tlearn: 0.9250903\ttotal: 14.4s\tremaining: 3.17s\n",
      "820:\tlearn: 0.9250424\ttotal: 14.5s\tremaining: 3.15s\n",
      "821:\tlearn: 0.9249516\ttotal: 14.5s\tremaining: 3.14s\n",
      "822:\tlearn: 0.9248952\ttotal: 14.5s\tremaining: 3.12s\n",
      "823:\tlearn: 0.9247943\ttotal: 14.5s\tremaining: 3.1s\n",
      "824:\tlearn: 0.9246950\ttotal: 14.5s\tremaining: 3.09s\n",
      "825:\tlearn: 0.9246008\ttotal: 14.6s\tremaining: 3.07s\n",
      "826:\tlearn: 0.9245641\ttotal: 14.6s\tremaining: 3.05s\n",
      "827:\tlearn: 0.9244920\ttotal: 14.6s\tremaining: 3.04s\n",
      "828:\tlearn: 0.9244476\ttotal: 14.6s\tremaining: 3.02s\n",
      "829:\tlearn: 0.9243768\ttotal: 14.7s\tremaining: 3s\n",
      "830:\tlearn: 0.9242638\ttotal: 14.7s\tremaining: 2.99s\n",
      "831:\tlearn: 0.9241849\ttotal: 14.7s\tremaining: 2.97s\n",
      "832:\tlearn: 0.9241329\ttotal: 14.7s\tremaining: 2.95s\n",
      "833:\tlearn: 0.9240668\ttotal: 14.7s\tremaining: 2.94s\n",
      "834:\tlearn: 0.9239157\ttotal: 14.8s\tremaining: 2.92s\n",
      "835:\tlearn: 0.9238617\ttotal: 14.8s\tremaining: 2.9s\n",
      "836:\tlearn: 0.9238153\ttotal: 14.8s\tremaining: 2.88s\n",
      "837:\tlearn: 0.9237756\ttotal: 14.8s\tremaining: 2.87s\n",
      "838:\tlearn: 0.9237549\ttotal: 14.8s\tremaining: 2.85s\n",
      "839:\tlearn: 0.9236828\ttotal: 14.9s\tremaining: 2.83s\n",
      "840:\tlearn: 0.9236152\ttotal: 14.9s\tremaining: 2.81s\n",
      "841:\tlearn: 0.9235647\ttotal: 14.9s\tremaining: 2.79s\n",
      "842:\tlearn: 0.9234596\ttotal: 14.9s\tremaining: 2.78s\n",
      "843:\tlearn: 0.9234003\ttotal: 14.9s\tremaining: 2.76s\n",
      "844:\tlearn: 0.9233336\ttotal: 14.9s\tremaining: 2.74s\n",
      "845:\tlearn: 0.9231902\ttotal: 15s\tremaining: 2.72s\n",
      "846:\tlearn: 0.9231275\ttotal: 15s\tremaining: 2.71s\n",
      "847:\tlearn: 0.9230979\ttotal: 15s\tremaining: 2.69s\n",
      "848:\tlearn: 0.9230004\ttotal: 15s\tremaining: 2.67s\n",
      "849:\tlearn: 0.9229548\ttotal: 15s\tremaining: 2.65s\n",
      "850:\tlearn: 0.9228637\ttotal: 15.1s\tremaining: 2.64s\n",
      "851:\tlearn: 0.9227598\ttotal: 15.1s\tremaining: 2.62s\n",
      "852:\tlearn: 0.9227288\ttotal: 15.1s\tremaining: 2.6s\n",
      "853:\tlearn: 0.9226708\ttotal: 15.1s\tremaining: 2.58s\n",
      "854:\tlearn: 0.9226066\ttotal: 15.1s\tremaining: 2.56s\n",
      "855:\tlearn: 0.9225638\ttotal: 15.1s\tremaining: 2.55s\n",
      "856:\tlearn: 0.9224505\ttotal: 15.2s\tremaining: 2.53s\n",
      "857:\tlearn: 0.9224263\ttotal: 15.2s\tremaining: 2.51s\n",
      "858:\tlearn: 0.9223722\ttotal: 15.2s\tremaining: 2.49s\n",
      "859:\tlearn: 0.9222506\ttotal: 15.2s\tremaining: 2.48s\n",
      "860:\tlearn: 0.9222146\ttotal: 15.2s\tremaining: 2.46s\n",
      "861:\tlearn: 0.9221757\ttotal: 15.2s\tremaining: 2.44s\n",
      "862:\tlearn: 0.9221229\ttotal: 15.3s\tremaining: 2.42s\n",
      "863:\tlearn: 0.9220314\ttotal: 15.3s\tremaining: 2.4s\n",
      "864:\tlearn: 0.9219858\ttotal: 15.3s\tremaining: 2.39s\n",
      "865:\tlearn: 0.9219496\ttotal: 15.3s\tremaining: 2.37s\n",
      "866:\tlearn: 0.9219167\ttotal: 15.3s\tremaining: 2.35s\n",
      "867:\tlearn: 0.9218308\ttotal: 15.4s\tremaining: 2.33s\n",
      "868:\tlearn: 0.9217972\ttotal: 15.4s\tremaining: 2.32s\n",
      "869:\tlearn: 0.9217338\ttotal: 15.4s\tremaining: 2.3s\n",
      "870:\tlearn: 0.9216717\ttotal: 15.4s\tremaining: 2.28s\n",
      "871:\tlearn: 0.9216136\ttotal: 15.4s\tremaining: 2.26s\n",
      "872:\tlearn: 0.9215423\ttotal: 15.4s\tremaining: 2.25s\n",
      "873:\tlearn: 0.9215083\ttotal: 15.5s\tremaining: 2.23s\n",
      "874:\tlearn: 0.9214335\ttotal: 15.5s\tremaining: 2.21s\n",
      "875:\tlearn: 0.9213521\ttotal: 15.5s\tremaining: 2.19s\n",
      "876:\tlearn: 0.9212792\ttotal: 15.5s\tremaining: 2.18s\n",
      "877:\tlearn: 0.9211969\ttotal: 15.5s\tremaining: 2.16s\n",
      "878:\tlearn: 0.9211270\ttotal: 15.6s\tremaining: 2.14s\n",
      "879:\tlearn: 0.9210756\ttotal: 15.6s\tremaining: 2.12s\n",
      "880:\tlearn: 0.9210217\ttotal: 15.6s\tremaining: 2.1s\n",
      "881:\tlearn: 0.9209295\ttotal: 15.6s\tremaining: 2.09s\n",
      "882:\tlearn: 0.9208840\ttotal: 15.6s\tremaining: 2.07s\n",
      "883:\tlearn: 0.9208333\ttotal: 15.6s\tremaining: 2.05s\n",
      "884:\tlearn: 0.9207915\ttotal: 15.7s\tremaining: 2.03s\n",
      "885:\tlearn: 0.9207142\ttotal: 15.7s\tremaining: 2.02s\n",
      "886:\tlearn: 0.9206603\ttotal: 15.7s\tremaining: 2s\n",
      "887:\tlearn: 0.9206126\ttotal: 15.7s\tremaining: 1.98s\n",
      "888:\tlearn: 0.9205288\ttotal: 15.7s\tremaining: 1.96s\n",
      "889:\tlearn: 0.9204682\ttotal: 15.8s\tremaining: 1.95s\n",
      "890:\tlearn: 0.9204032\ttotal: 15.8s\tremaining: 1.93s\n",
      "891:\tlearn: 0.9203244\ttotal: 15.8s\tremaining: 1.91s\n",
      "892:\tlearn: 0.9202679\ttotal: 15.8s\tremaining: 1.89s\n",
      "893:\tlearn: 0.9201236\ttotal: 15.8s\tremaining: 1.88s\n",
      "894:\tlearn: 0.9200496\ttotal: 15.8s\tremaining: 1.86s\n",
      "895:\tlearn: 0.9200101\ttotal: 15.9s\tremaining: 1.84s\n",
      "896:\tlearn: 0.9198946\ttotal: 15.9s\tremaining: 1.82s\n",
      "897:\tlearn: 0.9198151\ttotal: 15.9s\tremaining: 1.81s\n",
      "898:\tlearn: 0.9196878\ttotal: 15.9s\tremaining: 1.79s\n",
      "899:\tlearn: 0.9196103\ttotal: 15.9s\tremaining: 1.77s\n",
      "900:\tlearn: 0.9195199\ttotal: 16s\tremaining: 1.75s\n",
      "901:\tlearn: 0.9194431\ttotal: 16s\tremaining: 1.74s\n",
      "902:\tlearn: 0.9194023\ttotal: 16s\tremaining: 1.72s\n",
      "903:\tlearn: 0.9193260\ttotal: 16s\tremaining: 1.7s\n",
      "904:\tlearn: 0.9192707\ttotal: 16s\tremaining: 1.68s\n",
      "905:\tlearn: 0.9192172\ttotal: 16.1s\tremaining: 1.67s\n",
      "906:\tlearn: 0.9191337\ttotal: 16.1s\tremaining: 1.65s\n",
      "907:\tlearn: 0.9190167\ttotal: 16.1s\tremaining: 1.63s\n",
      "908:\tlearn: 0.9189577\ttotal: 16.1s\tremaining: 1.61s\n",
      "909:\tlearn: 0.9189201\ttotal: 16.1s\tremaining: 1.59s\n",
      "910:\tlearn: 0.9188907\ttotal: 16.1s\tremaining: 1.58s\n",
      "911:\tlearn: 0.9188373\ttotal: 16.2s\tremaining: 1.56s\n",
      "912:\tlearn: 0.9187815\ttotal: 16.2s\tremaining: 1.54s\n",
      "913:\tlearn: 0.9187421\ttotal: 16.2s\tremaining: 1.52s\n",
      "914:\tlearn: 0.9186338\ttotal: 16.2s\tremaining: 1.5s\n",
      "915:\tlearn: 0.9185870\ttotal: 16.2s\tremaining: 1.49s\n",
      "916:\tlearn: 0.9185447\ttotal: 16.2s\tremaining: 1.47s\n",
      "917:\tlearn: 0.9185002\ttotal: 16.3s\tremaining: 1.45s\n",
      "918:\tlearn: 0.9184398\ttotal: 16.3s\tremaining: 1.44s\n",
      "919:\tlearn: 0.9183679\ttotal: 16.3s\tremaining: 1.42s\n",
      "920:\tlearn: 0.9182522\ttotal: 16.3s\tremaining: 1.4s\n",
      "921:\tlearn: 0.9182229\ttotal: 16.4s\tremaining: 1.38s\n",
      "922:\tlearn: 0.9181356\ttotal: 16.4s\tremaining: 1.37s\n",
      "923:\tlearn: 0.9180949\ttotal: 16.4s\tremaining: 1.35s\n",
      "924:\tlearn: 0.9180245\ttotal: 16.4s\tremaining: 1.33s\n",
      "925:\tlearn: 0.9179658\ttotal: 16.4s\tremaining: 1.31s\n",
      "926:\tlearn: 0.9178678\ttotal: 16.5s\tremaining: 1.29s\n",
      "927:\tlearn: 0.9178159\ttotal: 16.5s\tremaining: 1.28s\n",
      "928:\tlearn: 0.9177445\ttotal: 16.5s\tremaining: 1.26s\n",
      "929:\tlearn: 0.9176458\ttotal: 16.5s\tremaining: 1.24s\n",
      "930:\tlearn: 0.9176096\ttotal: 16.5s\tremaining: 1.22s\n",
      "931:\tlearn: 0.9175552\ttotal: 16.5s\tremaining: 1.21s\n",
      "932:\tlearn: 0.9174957\ttotal: 16.6s\tremaining: 1.19s\n",
      "933:\tlearn: 0.9174267\ttotal: 16.6s\tremaining: 1.17s\n",
      "934:\tlearn: 0.9174074\ttotal: 16.6s\tremaining: 1.15s\n",
      "935:\tlearn: 0.9173534\ttotal: 16.6s\tremaining: 1.14s\n",
      "936:\tlearn: 0.9173002\ttotal: 16.6s\tremaining: 1.12s\n",
      "937:\tlearn: 0.9171954\ttotal: 16.6s\tremaining: 1.1s\n",
      "938:\tlearn: 0.9171357\ttotal: 16.7s\tremaining: 1.08s\n",
      "939:\tlearn: 0.9170532\ttotal: 16.7s\tremaining: 1.06s\n",
      "940:\tlearn: 0.9169873\ttotal: 16.7s\tremaining: 1.05s\n",
      "941:\tlearn: 0.9169305\ttotal: 16.7s\tremaining: 1.03s\n",
      "942:\tlearn: 0.9168950\ttotal: 16.7s\tremaining: 1.01s\n",
      "943:\tlearn: 0.9168099\ttotal: 16.7s\tremaining: 994ms\n",
      "944:\tlearn: 0.9167615\ttotal: 16.8s\tremaining: 976ms\n",
      "945:\tlearn: 0.9167203\ttotal: 16.8s\tremaining: 958ms\n",
      "946:\tlearn: 0.9166830\ttotal: 16.8s\tremaining: 940ms\n",
      "947:\tlearn: 0.9166023\ttotal: 16.8s\tremaining: 923ms\n",
      "948:\tlearn: 0.9165510\ttotal: 16.8s\tremaining: 905ms\n",
      "949:\tlearn: 0.9164771\ttotal: 16.9s\tremaining: 887ms\n",
      "950:\tlearn: 0.9163536\ttotal: 16.9s\tremaining: 870ms\n",
      "951:\tlearn: 0.9162664\ttotal: 16.9s\tremaining: 852ms\n",
      "952:\tlearn: 0.9162143\ttotal: 16.9s\tremaining: 834ms\n",
      "953:\tlearn: 0.9161014\ttotal: 16.9s\tremaining: 817ms\n",
      "954:\tlearn: 0.9160716\ttotal: 16.9s\tremaining: 799ms\n",
      "955:\tlearn: 0.9159771\ttotal: 17s\tremaining: 781ms\n",
      "956:\tlearn: 0.9159294\ttotal: 17s\tremaining: 763ms\n",
      "957:\tlearn: 0.9158491\ttotal: 17s\tremaining: 746ms\n",
      "958:\tlearn: 0.9158123\ttotal: 17s\tremaining: 728ms\n",
      "959:\tlearn: 0.9157313\ttotal: 17s\tremaining: 710ms\n",
      "960:\tlearn: 0.9156677\ttotal: 17.1s\tremaining: 693ms\n",
      "961:\tlearn: 0.9155882\ttotal: 17.1s\tremaining: 675ms\n",
      "962:\tlearn: 0.9155103\ttotal: 17.1s\tremaining: 657ms\n",
      "963:\tlearn: 0.9153968\ttotal: 17.1s\tremaining: 639ms\n",
      "964:\tlearn: 0.9153456\ttotal: 17.1s\tremaining: 622ms\n",
      "965:\tlearn: 0.9152782\ttotal: 17.2s\tremaining: 604ms\n",
      "966:\tlearn: 0.9152208\ttotal: 17.2s\tremaining: 586ms\n",
      "967:\tlearn: 0.9151232\ttotal: 17.2s\tremaining: 569ms\n",
      "968:\tlearn: 0.9150692\ttotal: 17.2s\tremaining: 551ms\n",
      "969:\tlearn: 0.9150521\ttotal: 17.2s\tremaining: 533ms\n",
      "970:\tlearn: 0.9150145\ttotal: 17.3s\tremaining: 515ms\n",
      "971:\tlearn: 0.9149830\ttotal: 17.3s\tremaining: 498ms\n",
      "972:\tlearn: 0.9149047\ttotal: 17.3s\tremaining: 480ms\n",
      "973:\tlearn: 0.9148534\ttotal: 17.3s\tremaining: 462ms\n",
      "974:\tlearn: 0.9147680\ttotal: 17.3s\tremaining: 444ms\n",
      "975:\tlearn: 0.9147233\ttotal: 17.3s\tremaining: 427ms\n",
      "976:\tlearn: 0.9147072\ttotal: 17.4s\tremaining: 409ms\n",
      "977:\tlearn: 0.9146633\ttotal: 17.4s\tremaining: 391ms\n",
      "978:\tlearn: 0.9145993\ttotal: 17.4s\tremaining: 373ms\n",
      "979:\tlearn: 0.9145517\ttotal: 17.4s\tremaining: 355ms\n",
      "980:\tlearn: 0.9144331\ttotal: 17.4s\tremaining: 338ms\n",
      "981:\tlearn: 0.9144144\ttotal: 17.5s\tremaining: 320ms\n",
      "982:\tlearn: 0.9143261\ttotal: 17.5s\tremaining: 302ms\n",
      "983:\tlearn: 0.9142356\ttotal: 17.5s\tremaining: 284ms\n",
      "984:\tlearn: 0.9141855\ttotal: 17.5s\tremaining: 267ms\n",
      "985:\tlearn: 0.9140948\ttotal: 17.5s\tremaining: 249ms\n",
      "986:\tlearn: 0.9140679\ttotal: 17.5s\tremaining: 231ms\n",
      "987:\tlearn: 0.9140038\ttotal: 17.6s\tremaining: 213ms\n",
      "988:\tlearn: 0.9139496\ttotal: 17.6s\tremaining: 195ms\n",
      "989:\tlearn: 0.9138823\ttotal: 17.6s\tremaining: 178ms\n",
      "990:\tlearn: 0.9138358\ttotal: 17.6s\tremaining: 160ms\n",
      "991:\tlearn: 0.9137729\ttotal: 17.6s\tremaining: 142ms\n",
      "992:\tlearn: 0.9136822\ttotal: 17.7s\tremaining: 124ms\n",
      "993:\tlearn: 0.9136418\ttotal: 17.7s\tremaining: 107ms\n",
      "994:\tlearn: 0.9135550\ttotal: 17.7s\tremaining: 88.9ms\n",
      "995:\tlearn: 0.9135141\ttotal: 17.7s\tremaining: 71.1ms\n",
      "996:\tlearn: 0.9134221\ttotal: 17.7s\tremaining: 53.3ms\n",
      "997:\tlearn: 0.9133500\ttotal: 17.7s\tremaining: 35.5ms\n",
      "998:\tlearn: 0.9132840\ttotal: 17.8s\tremaining: 17.8ms\n",
      "999:\tlearn: 0.9132320\ttotal: 17.8s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostRegressor at 0x1b3274332b0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "cbr = CatBoostRegressor()\n",
    "cbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error :->  0.6805825687792022\n",
      "Mean Squared Error :->  0.8987441065712328\n",
      "Root Mean Squared Error :->  0.9480211530188727\n",
      "R-Square :->  0.8183012700467944\n"
     ]
    }
   ],
   "source": [
    "y_pred_cat = cbr.predict(X_test)\n",
    "mae, mse, rmse, r2 = evaluate(y_test, y_pred_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_score['CatBoost'] = r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy of Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,8))\n",
    "sns.barplot(x=list(algo_score.keys()), y=list(algo_score.values()))\n",
    "plt.title(\"Algorithms Performance\")\n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"R-Squared Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ---> 0.8128859709004848\n",
      "K Nearest Neighbour ---> 0.7530723645360814\n",
      "Linear Regression ---> 0.6347610251786897\n",
      "Decision Tree ---> 0.6771680509260982\n",
      "XG Boost ---> 0.812554056935533\n",
      "Optimized XG Boost ---> 0.8170610040695809\n",
      "ANN ---> 0.783089789445651\n",
      "CatBoost ---> 0.8183012700467944\n"
     ]
    }
   ],
   "source": [
    "for key, val in algo_score.items():\n",
    "    print(key, '--->', val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best performing Model is CatBoost Regressor"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ddfba760c93d0781cb88c4db9a31eb68ca4e1616821530f19d735f356a5c9ec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
